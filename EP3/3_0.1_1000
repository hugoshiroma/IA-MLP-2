Pesos Camada de Entrada: 
[[-0.06989507  0.20810793 -0.12092721]
 [ 0.0164623  -0.19993122 -0.01715178]
 [ 0.13002859 -0.017169   -0.22153237]
 [ 0.06882108  0.18977886  0.04439414]
 [-0.15913953 -0.08566062  0.11072784]
 [-0.19931929  0.00729603 -0.01270726]
 [ 0.15113108 -0.21578979  0.15837336]
 [ 0.03751672 -0.12063947  0.05791139]
 [-0.22236698 -0.08199392 -0.19898526]
 [-0.1623481   0.22455813 -0.17365075]
 [-0.11673215  0.17674219 -0.13161982]
 [-0.12560957 -0.12850162  0.17140757]
 [-0.19606175 -0.21688262 -0.17081713]
 [ 0.04056683 -0.02238634 -0.11048479]
 [-0.2147971  -0.11039543  0.17528768]
 [-0.03752863 -0.19019587  0.19430529]
 [-0.13738301  0.01472105 -0.01347036]
 [-0.03110175  0.10442147 -0.01084828]
 [ 0.06678138  0.12286669  0.05560806]
 [-0.11857381 -0.16945067 -0.1982103 ]
 [ 0.15848953  0.00617292 -0.22251809]
 [-0.21332814  0.062661   -0.15776957]
 [ 0.17733909 -0.16285921 -0.05545315]
 [-0.17795444 -0.02135691  0.08893203]
 [ 0.16020223  0.16867862  0.13066142]
 [ 0.00557717  0.00277255  0.03532874]
 [ 0.18704708  0.18776359  0.19400004]
 [-0.12751716 -0.2268155   0.03339126]
 [ 0.11912936 -0.13397383  0.01743507]
 [-0.08808718  0.0536558   0.07324381]
 [-0.15077464  0.00379631  0.10428847]
 [ 0.00887314  0.0537745  -0.18234922]
 [-0.02840388 -0.05642482 -0.09628413]
 [ 0.15187369  0.12778164 -0.12975217]]
Bias Camada de Entrada: 
[-0.00235065 -0.04216806  0.0147725 ]
Pesos Camada Escondida: 
[[ 0.36369543]
 [ 0.23308061]
 [-0.40758333]]
Bias Camada Escondida: 
[-0.01286201]
Iteration 1, loss = 0.68530001
Iteration 2, loss = 0.67417773
Iteration 3, loss = 0.66368901
Iteration 4, loss = 0.65407451
Iteration 5, loss = 0.64909815
Iteration 6, loss = 0.64593049
Iteration 7, loss = 0.64231008
Iteration 8, loss = 0.63935667
Iteration 9, loss = 0.63552021
Iteration 10, loss = 0.63037900
Iteration 11, loss = 0.62482513
Iteration 12, loss = 0.61967307
Iteration 13, loss = 0.61501805
Iteration 14, loss = 0.60923318
Iteration 15, loss = 0.60289472
Iteration 16, loss = 0.59629222
Iteration 17, loss = 0.58959902
Iteration 18, loss = 0.58228658
Iteration 19, loss = 0.57415065
Iteration 20, loss = 0.56575528
Iteration 21, loss = 0.55611361
Iteration 22, loss = 0.54777942
Iteration 23, loss = 0.53774491
Iteration 24, loss = 0.52790229
Iteration 25, loss = 0.51735648
Iteration 26, loss = 0.50709289
Iteration 27, loss = 0.49668973
Iteration 28, loss = 0.48674941
Iteration 29, loss = 0.47716464
Iteration 30, loss = 0.46666365
Iteration 31, loss = 0.45767931
Iteration 32, loss = 0.44848632
Iteration 33, loss = 0.43912896
Iteration 34, loss = 0.43076454
Iteration 35, loss = 0.42243758
Iteration 36, loss = 0.41425183
Iteration 37, loss = 0.40731030
Iteration 38, loss = 0.40005384
Iteration 39, loss = 0.39416403
Iteration 40, loss = 0.38905308
Iteration 41, loss = 0.38398005
Iteration 42, loss = 0.37783272
Iteration 43, loss = 0.37231746
Iteration 44, loss = 0.36784379
Iteration 45, loss = 0.36343169
Iteration 46, loss = 0.35935873
Iteration 47, loss = 0.35530463
Iteration 48, loss = 0.35249653
Iteration 49, loss = 0.34827479
Iteration 50, loss = 0.34400976
Iteration 51, loss = 0.34011579
Iteration 52, loss = 0.33639134
Iteration 53, loss = 0.33309487
Iteration 54, loss = 0.32991612
Iteration 55, loss = 0.32668257
Iteration 56, loss = 0.32354440
Iteration 57, loss = 0.32019596
Iteration 58, loss = 0.31771043
Iteration 59, loss = 0.31514519
Iteration 60, loss = 0.31215503
Iteration 61, loss = 0.30947513
Iteration 62, loss = 0.30685935
Iteration 63, loss = 0.30492135
Iteration 64, loss = 0.30323497
Iteration 65, loss = 0.30067063
Iteration 66, loss = 0.29850431
Iteration 67, loss = 0.29622931
Iteration 68, loss = 0.29463715
Iteration 69, loss = 0.29351746
Iteration 70, loss = 0.29163593
Iteration 71, loss = 0.28854141
Iteration 72, loss = 0.28684950
Iteration 73, loss = 0.28497040
Iteration 74, loss = 0.28363912
Iteration 75, loss = 0.28230117
Iteration 76, loss = 0.27892852
Iteration 77, loss = 0.27840761
Iteration 78, loss = 0.27706133
Iteration 79, loss = 0.27474532
Iteration 80, loss = 0.27270189
Iteration 81, loss = 0.27168685
Iteration 82, loss = 0.27094590
Iteration 83, loss = 0.26884694
Iteration 84, loss = 0.26704048
Iteration 85, loss = 0.26554990
Iteration 86, loss = 0.26428055
Iteration 87, loss = 0.26296467
Iteration 88, loss = 0.26236492
Iteration 89, loss = 0.26241449
Iteration 90, loss = 0.26067685
Iteration 91, loss = 0.25713799
Iteration 92, loss = 0.25616728
Iteration 93, loss = 0.25550007
Iteration 94, loss = 0.25416390
Iteration 95, loss = 0.25230546
Iteration 96, loss = 0.25085434
Iteration 97, loss = 0.25021882
Iteration 98, loss = 0.24877925
Iteration 99, loss = 0.24770948
Iteration 100, loss = 0.24657068
Iteration 101, loss = 0.24621963
Iteration 102, loss = 0.24504307
Iteration 103, loss = 0.24342373
Iteration 104, loss = 0.24209668
Iteration 105, loss = 0.24078719
Iteration 106, loss = 0.23965120
Iteration 107, loss = 0.23872775
Iteration 108, loss = 0.23770479
Iteration 109, loss = 0.23731323
Iteration 110, loss = 0.23636464
Iteration 111, loss = 0.23529652
Iteration 112, loss = 0.23484685
Iteration 113, loss = 0.23461333
Iteration 114, loss = 0.23231932
Iteration 115, loss = 0.23052655
Iteration 116, loss = 0.22909251
Iteration 117, loss = 0.22802567
Iteration 118, loss = 0.22703163
Iteration 119, loss = 0.22622393
Iteration 120, loss = 0.22493601
Iteration 121, loss = 0.22420329
Iteration 122, loss = 0.22310325
Iteration 123, loss = 0.22206882
Iteration 124, loss = 0.22117999
Iteration 125, loss = 0.22014202
Iteration 126, loss = 0.21910814
Iteration 127, loss = 0.21838551
Iteration 128, loss = 0.21771719
Iteration 129, loss = 0.21666590
Iteration 130, loss = 0.21572422
Iteration 131, loss = 0.21456640
Iteration 132, loss = 0.21330501
Iteration 133, loss = 0.21201110
Iteration 134, loss = 0.21119164
Iteration 135, loss = 0.21038120
Iteration 136, loss = 0.20973438
Iteration 137, loss = 0.20895088
Iteration 138, loss = 0.20763290
Iteration 139, loss = 0.20601743
Iteration 140, loss = 0.20490570
Iteration 141, loss = 0.20396620
Iteration 142, loss = 0.20323523
Iteration 143, loss = 0.20214686
Iteration 144, loss = 0.20105184
Iteration 145, loss = 0.20013908
Iteration 146, loss = 0.19902374
Iteration 147, loss = 0.19803558
Iteration 148, loss = 0.19692477
Iteration 149, loss = 0.19583293
Iteration 150, loss = 0.19478433
Iteration 151, loss = 0.19382678
Iteration 152, loss = 0.19309483
Iteration 153, loss = 0.19185509
Iteration 154, loss = 0.19080173
Iteration 155, loss = 0.19001051
Iteration 156, loss = 0.18903196
Iteration 157, loss = 0.18815960
Iteration 158, loss = 0.18745684
Iteration 159, loss = 0.18688287
Iteration 160, loss = 0.18637630
Iteration 161, loss = 0.18584058
Iteration 162, loss = 0.18471799
Iteration 163, loss = 0.18301737
Iteration 164, loss = 0.18170125
Iteration 165, loss = 0.18081930
Iteration 166, loss = 0.17986097
Iteration 167, loss = 0.17882069
Iteration 168, loss = 0.17801609
Iteration 169, loss = 0.17763443
Iteration 170, loss = 0.17730015
Iteration 171, loss = 0.17670957
Iteration 172, loss = 0.17496807
Iteration 173, loss = 0.17377301
Iteration 174, loss = 0.17288243
Iteration 175, loss = 0.17213946
Iteration 176, loss = 0.17121026
Iteration 177, loss = 0.17037350
Iteration 178, loss = 0.16965146
Iteration 179, loss = 0.16881484
Iteration 180, loss = 0.16817024
Iteration 181, loss = 0.16760900
Iteration 182, loss = 0.16719208
Iteration 183, loss = 0.16703217
Iteration 184, loss = 0.16577398
Iteration 185, loss = 0.16537404
Iteration 186, loss = 0.16416106
Iteration 187, loss = 0.16349568
Iteration 188, loss = 0.16276545
Iteration 189, loss = 0.16190733
Iteration 190, loss = 0.16099990
Iteration 191, loss = 0.16027748
Iteration 192, loss = 0.15974177
Iteration 193, loss = 0.15923571
Iteration 194, loss = 0.15854311
Iteration 195, loss = 0.15719582
Iteration 196, loss = 0.15634539
Iteration 197, loss = 0.15627902
Iteration 198, loss = 0.15534666
Iteration 199, loss = 0.15450411
Iteration 200, loss = 0.15392242
Iteration 201, loss = 0.15333714
Iteration 202, loss = 0.15271387
Iteration 203, loss = 0.15203430
Iteration 204, loss = 0.15136483
Iteration 205, loss = 0.15055769
Iteration 206, loss = 0.15002787
Iteration 207, loss = 0.14933453
Iteration 208, loss = 0.14869279
Iteration 209, loss = 0.14809991
Iteration 210, loss = 0.14783158
Iteration 211, loss = 0.14834739
Iteration 212, loss = 0.14743810
Iteration 213, loss = 0.14678983
Iteration 214, loss = 0.14599923
Iteration 215, loss = 0.14500942
Iteration 216, loss = 0.14426384
Iteration 217, loss = 0.14368010
Iteration 218, loss = 0.14299093
Iteration 219, loss = 0.14275557
Iteration 220, loss = 0.14218685
Iteration 221, loss = 0.14172125
Iteration 222, loss = 0.14118857
Iteration 223, loss = 0.14041614
Iteration 224, loss = 0.13953785
Iteration 225, loss = 0.13879191
Iteration 226, loss = 0.13855398
Iteration 227, loss = 0.13770381
Iteration 228, loss = 0.13736281
Iteration 229, loss = 0.13667816
Iteration 230, loss = 0.13619024
Iteration 231, loss = 0.13554644
Iteration 232, loss = 0.13503340
Iteration 233, loss = 0.13469700
Iteration 234, loss = 0.13418891
Iteration 235, loss = 0.13377644
Iteration 236, loss = 0.13367385
Iteration 237, loss = 0.13321351
Iteration 238, loss = 0.13390953
Iteration 239, loss = 0.13321556
Iteration 240, loss = 0.13222623
Iteration 241, loss = 0.13132459
Iteration 242, loss = 0.13049758
Iteration 243, loss = 0.13002264
Iteration 244, loss = 0.12952316
Iteration 245, loss = 0.12939683
Iteration 246, loss = 0.12893287
Iteration 247, loss = 0.12844065
Iteration 248, loss = 0.12795173
Iteration 249, loss = 0.12779771
Iteration 250, loss = 0.12762189
Iteration 251, loss = 0.12721785
Iteration 252, loss = 0.12652498
Iteration 253, loss = 0.12578936
Iteration 254, loss = 0.12523385
Iteration 255, loss = 0.12519372
Iteration 256, loss = 0.12472870
Iteration 257, loss = 0.12421987
Iteration 258, loss = 0.12358968
Iteration 259, loss = 0.12318394
Iteration 260, loss = 0.12277892
Iteration 261, loss = 0.12245704
Iteration 262, loss = 0.12211359
Iteration 263, loss = 0.12175183
Iteration 264, loss = 0.12152750
Iteration 265, loss = 0.12145097
Iteration 266, loss = 0.12115281
Iteration 267, loss = 0.12096105
Iteration 268, loss = 0.12050401
Iteration 269, loss = 0.12000143
Iteration 270, loss = 0.11964310
Iteration 271, loss = 0.11924793
Iteration 272, loss = 0.11899795
Iteration 273, loss = 0.11882023
Iteration 274, loss = 0.11838289
Iteration 275, loss = 0.11777737
Iteration 276, loss = 0.11727620
Iteration 277, loss = 0.11666499
Iteration 278, loss = 0.11645123
Iteration 279, loss = 0.11695742
Iteration 280, loss = 0.11682604
Iteration 281, loss = 0.11590817
Iteration 282, loss = 0.11549578
Iteration 283, loss = 0.11485786
Iteration 284, loss = 0.11537157
Iteration 285, loss = 0.11435136
Iteration 286, loss = 0.11405507
Iteration 287, loss = 0.11352577
Iteration 288, loss = 0.11313695
Iteration 289, loss = 0.11253005
Iteration 290, loss = 0.11208364
Iteration 291, loss = 0.11176284
Iteration 292, loss = 0.11138775
Iteration 293, loss = 0.11094670
Iteration 294, loss = 0.11075849
Iteration 295, loss = 0.11042338
Iteration 296, loss = 0.11001652
Iteration 297, loss = 0.10988359
Iteration 298, loss = 0.10936963
Iteration 299, loss = 0.10908901
Iteration 300, loss = 0.10889327
Iteration 301, loss = 0.10874799
Iteration 302, loss = 0.10855070
Iteration 303, loss = 0.10798805
Iteration 304, loss = 0.10735368
Iteration 305, loss = 0.10680937
Iteration 306, loss = 0.10680562
Iteration 307, loss = 0.10637320
Iteration 308, loss = 0.10609527
Iteration 309, loss = 0.10576264
Iteration 310, loss = 0.10543042
Iteration 311, loss = 0.10507050
Iteration 312, loss = 0.10472156
Iteration 313, loss = 0.10429571
Iteration 314, loss = 0.10428439
Iteration 315, loss = 0.10376485
Iteration 316, loss = 0.10332010
Iteration 317, loss = 0.10297221
Iteration 318, loss = 0.10302643
Iteration 319, loss = 0.10228624
Iteration 320, loss = 0.10223338
Iteration 321, loss = 0.10181653
Iteration 322, loss = 0.10138015
Iteration 323, loss = 0.10095864
Iteration 324, loss = 0.10056280
Iteration 325, loss = 0.10035168
Iteration 326, loss = 0.10005214
Iteration 327, loss = 0.09959434
Iteration 328, loss = 0.09927181
Iteration 329, loss = 0.09897470
Iteration 330, loss = 0.09877382
Iteration 331, loss = 0.09876613
Iteration 332, loss = 0.09815487
Iteration 333, loss = 0.09769686
Iteration 334, loss = 0.09742995
Iteration 335, loss = 0.09724106
Iteration 336, loss = 0.09699226
Iteration 337, loss = 0.09661484
Iteration 338, loss = 0.09643516
Iteration 339, loss = 0.09608713
Iteration 340, loss = 0.09583533
Iteration 341, loss = 0.09529424
Iteration 342, loss = 0.09506592
Iteration 343, loss = 0.09545691
Iteration 344, loss = 0.09545265
Iteration 345, loss = 0.09484777
Iteration 346, loss = 0.09425504
Iteration 347, loss = 0.09323433
Iteration 348, loss = 0.09278368
Iteration 349, loss = 0.09247702
Iteration 350, loss = 0.09250376
Iteration 351, loss = 0.09198235
Iteration 352, loss = 0.09175794
Iteration 353, loss = 0.09146057
Iteration 354, loss = 0.09107924
Iteration 355, loss = 0.09070921
Iteration 356, loss = 0.09049519
Iteration 357, loss = 0.08977782
Iteration 358, loss = 0.08980154
Iteration 359, loss = 0.08939930
Iteration 360, loss = 0.08909120
Iteration 361, loss = 0.08832456
Iteration 362, loss = 0.08819164
Iteration 363, loss = 0.08823959
Iteration 364, loss = 0.08841567
Iteration 365, loss = 0.08827751
Iteration 366, loss = 0.08777162
Iteration 367, loss = 0.08720200
Iteration 368, loss = 0.08650325
Iteration 369, loss = 0.08594833
Iteration 370, loss = 0.08616584
Iteration 371, loss = 0.08580083
Iteration 372, loss = 0.08574864
Iteration 373, loss = 0.08623311
Iteration 374, loss = 0.08578956
Iteration 375, loss = 0.08521074
Iteration 376, loss = 0.08456071
Iteration 377, loss = 0.08395888
Iteration 378, loss = 0.08345176
Iteration 379, loss = 0.08334866
Iteration 380, loss = 0.08284267
Iteration 381, loss = 0.08261778
Iteration 382, loss = 0.08217948
Iteration 383, loss = 0.08181207
Iteration 384, loss = 0.08158599
Iteration 385, loss = 0.08153644
Iteration 386, loss = 0.08116519
Iteration 387, loss = 0.08086852
Iteration 388, loss = 0.08082883
Iteration 389, loss = 0.08025859
Iteration 390, loss = 0.07993013
Iteration 391, loss = 0.07980732
Iteration 392, loss = 0.07954089
Iteration 393, loss = 0.07927332
Iteration 394, loss = 0.07887531
Iteration 395, loss = 0.07879308
Iteration 396, loss = 0.07899173
Iteration 397, loss = 0.07874927
Iteration 398, loss = 0.07860535
Iteration 399, loss = 0.07843075
Iteration 400, loss = 0.07826260
Iteration 401, loss = 0.07766141
Iteration 402, loss = 0.07722970
Iteration 403, loss = 0.07693063
Iteration 404, loss = 0.07702451
Iteration 405, loss = 0.07682241
Iteration 406, loss = 0.07678776
Iteration 407, loss = 0.07605554
Iteration 408, loss = 0.07558488
Iteration 409, loss = 0.07519283
Iteration 410, loss = 0.07526808
Iteration 411, loss = 0.07505828
Iteration 412, loss = 0.07488347
Iteration 413, loss = 0.07471803
Iteration 414, loss = 0.07468292
Iteration 415, loss = 0.07414251
Iteration 416, loss = 0.07376697
Iteration 417, loss = 0.07363557
Iteration 418, loss = 0.07358068
Iteration 419, loss = 0.07363882
Iteration 420, loss = 0.07351181
Iteration 421, loss = 0.07327098
Iteration 422, loss = 0.07264879
Iteration 423, loss = 0.07211729
Iteration 424, loss = 0.07197685
Iteration 425, loss = 0.07231722
Iteration 426, loss = 0.07181052
Iteration 427, loss = 0.07142310
Iteration 428, loss = 0.07126755
Iteration 429, loss = 0.07098221
Iteration 430, loss = 0.07079433
Iteration 431, loss = 0.07067720
Iteration 432, loss = 0.07044400
Iteration 433, loss = 0.07035548
Iteration 434, loss = 0.07025477
Iteration 435, loss = 0.07020041
Iteration 436, loss = 0.06999868
Iteration 437, loss = 0.06977865
Iteration 438, loss = 0.06952363
Iteration 439, loss = 0.06923465
Iteration 440, loss = 0.06894799
Iteration 441, loss = 0.06863803
Iteration 442, loss = 0.06839290
Iteration 443, loss = 0.06835414
Iteration 444, loss = 0.06802155
Iteration 445, loss = 0.06773957
Iteration 446, loss = 0.06767103
Iteration 447, loss = 0.06742280
Iteration 448, loss = 0.06735315
Iteration 449, loss = 0.06720221
Iteration 450, loss = 0.06729221
Iteration 451, loss = 0.06713363
Iteration 452, loss = 0.06701973
Iteration 453, loss = 0.06649302
Iteration 454, loss = 0.06621033
Iteration 455, loss = 0.06640726
Iteration 456, loss = 0.06626931
Iteration 457, loss = 0.06619076
Iteration 458, loss = 0.06592903
Iteration 459, loss = 0.06561995
Iteration 460, loss = 0.06522360
Iteration 461, loss = 0.06486259
Iteration 462, loss = 0.06467032
Iteration 463, loss = 0.06480045
Iteration 464, loss = 0.06522326
Iteration 465, loss = 0.06509099
Iteration 466, loss = 0.06432697
Iteration 467, loss = 0.06421295
Iteration 468, loss = 0.06365850
Iteration 469, loss = 0.06346459
Iteration 470, loss = 0.06324462
Iteration 471, loss = 0.06311356
Iteration 472, loss = 0.06292448
Iteration 473, loss = 0.06352610
Iteration 474, loss = 0.06323790
Iteration 475, loss = 0.06284699
Iteration 476, loss = 0.06229397
Iteration 477, loss = 0.06231377
Iteration 478, loss = 0.06173108
Iteration 479, loss = 0.06160776
Iteration 480, loss = 0.06154426
Iteration 481, loss = 0.06130480
Iteration 482, loss = 0.06119317
Iteration 483, loss = 0.06101169
Iteration 484, loss = 0.06089272
Iteration 485, loss = 0.06070674
Iteration 486, loss = 0.06063740
Iteration 487, loss = 0.06050741
Iteration 488, loss = 0.06042054
Iteration 489, loss = 0.06030730
Iteration 490, loss = 0.06007840
Iteration 491, loss = 0.05985660
Iteration 492, loss = 0.05963076
Iteration 493, loss = 0.05926665
Iteration 494, loss = 0.05960127
Iteration 495, loss = 0.05948492
Iteration 496, loss = 0.05912270
Iteration 497, loss = 0.05879831
Iteration 498, loss = 0.05879965
Iteration 499, loss = 0.05844721
Iteration 500, loss = 0.05826776
Iteration 501, loss = 0.05833399
Iteration 502, loss = 0.05835851
Iteration 503, loss = 0.05843936
Iteration 504, loss = 0.05848821
Iteration 505, loss = 0.05831890
Iteration 506, loss = 0.05769957
Iteration 507, loss = 0.05722809
Iteration 508, loss = 0.05707843
Iteration 509, loss = 0.05688795
Iteration 510, loss = 0.05675276
Iteration 511, loss = 0.05692087
Iteration 512, loss = 0.05697746
Iteration 513, loss = 0.05706910
Iteration 514, loss = 0.05678778
Iteration 515, loss = 0.05668578
Iteration 516, loss = 0.05633683
Iteration 517, loss = 0.05603974
Iteration 518, loss = 0.05582725
Iteration 519, loss = 0.05554862
Iteration 520, loss = 0.05532765
Iteration 521, loss = 0.05515514
Iteration 522, loss = 0.05501442
Iteration 523, loss = 0.05479448
Iteration 524, loss = 0.05467208
Iteration 525, loss = 0.05450316
Iteration 526, loss = 0.05440521
Iteration 527, loss = 0.05438295
Iteration 528, loss = 0.05429643
Iteration 529, loss = 0.05438498
Iteration 530, loss = 0.05444339
Iteration 531, loss = 0.05452516
Iteration 532, loss = 0.05439143
Iteration 533, loss = 0.05426610
Iteration 534, loss = 0.05418489
Iteration 535, loss = 0.05421408
Iteration 536, loss = 0.05405044
Iteration 537, loss = 0.05389786
Iteration 538, loss = 0.05361607
Iteration 539, loss = 0.05349556
Iteration 540, loss = 0.05380431
Iteration 541, loss = 0.05312449
Iteration 542, loss = 0.05250256
Iteration 543, loss = 0.05210564
Iteration 544, loss = 0.05200678
Iteration 545, loss = 0.05207688
Iteration 546, loss = 0.05196317
Iteration 547, loss = 0.05186577
Iteration 548, loss = 0.05147051
Iteration 549, loss = 0.05115067
Iteration 550, loss = 0.05128292
Iteration 551, loss = 0.05114796
Iteration 552, loss = 0.05127058
Iteration 553, loss = 0.05141514
Iteration 554, loss = 0.05111276
Iteration 555, loss = 0.05098544
Iteration 556, loss = 0.05075782
Iteration 557, loss = 0.05028046
Iteration 558, loss = 0.05011375
Iteration 559, loss = 0.05020064
Iteration 560, loss = 0.05026822
Iteration 561, loss = 0.05027344
Iteration 562, loss = 0.05037855
Iteration 563, loss = 0.05052205
Iteration 564, loss = 0.05062882
Iteration 565, loss = 0.05048245
Iteration 566, loss = 0.04997582
Iteration 567, loss = 0.04941064
Iteration 568, loss = 0.04972510
Iteration 569, loss = 0.04934731
Iteration 570, loss = 0.04921681
Iteration 571, loss = 0.04909011
Iteration 572, loss = 0.04913899
Iteration 573, loss = 0.04876198
Iteration 574, loss = 0.04851549
Iteration 575, loss = 0.04820926
Iteration 576, loss = 0.04814399
Iteration 577, loss = 0.04802176
Iteration 578, loss = 0.04798719
Iteration 579, loss = 0.04784038
Iteration 580, loss = 0.04786091
Iteration 581, loss = 0.04779842
Iteration 582, loss = 0.04773477
Iteration 583, loss = 0.04755382
Iteration 584, loss = 0.04742196
Iteration 585, loss = 0.04739648
Iteration 586, loss = 0.04708811
Iteration 587, loss = 0.04706555
Iteration 588, loss = 0.04686629
Iteration 589, loss = 0.04682864
Iteration 590, loss = 0.04690569
Iteration 591, loss = 0.04670770
Iteration 592, loss = 0.04650279
Iteration 593, loss = 0.04632902
Iteration 594, loss = 0.04624138
Iteration 595, loss = 0.04607349
Iteration 596, loss = 0.04600848
Iteration 597, loss = 0.04595735
Iteration 598, loss = 0.04589307
Iteration 599, loss = 0.04580703
Iteration 600, loss = 0.04580354
Iteration 601, loss = 0.04566154
Iteration 602, loss = 0.04565525
Iteration 603, loss = 0.04560215
Iteration 604, loss = 0.04551681
Iteration 605, loss = 0.04548836
Iteration 606, loss = 0.04531154
Iteration 607, loss = 0.04526888
Iteration 608, loss = 0.04517352
Iteration 609, loss = 0.04514395
Iteration 610, loss = 0.04481433
Iteration 611, loss = 0.04462235
Iteration 612, loss = 0.04468600
Iteration 613, loss = 0.04497734
Iteration 614, loss = 0.04494475
Iteration 615, loss = 0.04475136
Iteration 616, loss = 0.04449138
Iteration 617, loss = 0.04426779
Iteration 618, loss = 0.04397516
Iteration 619, loss = 0.04384073
Iteration 620, loss = 0.04380504
Iteration 621, loss = 0.04376389
Iteration 622, loss = 0.04374060
Iteration 623, loss = 0.04364537
Iteration 624, loss = 0.04351505
Iteration 625, loss = 0.04339777
Iteration 626, loss = 0.04326792
Iteration 627, loss = 0.04321700
Iteration 628, loss = 0.04309602
Iteration 629, loss = 0.04290131
Iteration 630, loss = 0.04271009
Iteration 631, loss = 0.04252366
Iteration 632, loss = 0.04236555
Iteration 633, loss = 0.04229619
Iteration 634, loss = 0.04226073
Iteration 635, loss = 0.04235520
Iteration 636, loss = 0.04212252
Iteration 637, loss = 0.04197946
Iteration 638, loss = 0.04174323
Iteration 639, loss = 0.04167986
Iteration 640, loss = 0.04172014
Iteration 641, loss = 0.04186972
Iteration 642, loss = 0.04154615
Iteration 643, loss = 0.04159666
Iteration 644, loss = 0.04129225
Iteration 645, loss = 0.04122769
Iteration 646, loss = 0.04120943
Iteration 647, loss = 0.04094781
Iteration 648, loss = 0.04092134
Iteration 649, loss = 0.04082222
Iteration 650, loss = 0.04070390
Iteration 651, loss = 0.04056475
Iteration 652, loss = 0.04052436
Iteration 653, loss = 0.04045398
Iteration 654, loss = 0.04040329
Iteration 655, loss = 0.04026742
Iteration 656, loss = 0.04013406
Iteration 657, loss = 0.04004701
Iteration 658, loss = 0.03999321
Iteration 659, loss = 0.03991846
Iteration 660, loss = 0.03987496
Iteration 661, loss = 0.03984429
Iteration 662, loss = 0.03980350
Iteration 663, loss = 0.03976688
Iteration 664, loss = 0.03962553
Iteration 665, loss = 0.03956652
Iteration 666, loss = 0.03944536
Iteration 667, loss = 0.03932052
Iteration 668, loss = 0.03926038
Iteration 669, loss = 0.03918515
Iteration 670, loss = 0.03901735
Iteration 671, loss = 0.03890510
Iteration 672, loss = 0.03885590
Iteration 673, loss = 0.03874039
Iteration 674, loss = 0.03868342
Iteration 675, loss = 0.03853070
Iteration 676, loss = 0.03852358
Iteration 677, loss = 0.03844999
Iteration 678, loss = 0.03843006
Iteration 679, loss = 0.03827180
Iteration 680, loss = 0.03806571
Iteration 681, loss = 0.03793389
Iteration 682, loss = 0.03786929
Iteration 683, loss = 0.03787319
Iteration 684, loss = 0.03777358
Iteration 685, loss = 0.03777831
Iteration 686, loss = 0.03770553
Iteration 687, loss = 0.03750758
Iteration 688, loss = 0.03742874
Iteration 689, loss = 0.03736505
Iteration 690, loss = 0.03724483
Iteration 691, loss = 0.03716798
Iteration 692, loss = 0.03707896
Iteration 693, loss = 0.03706569
Iteration 694, loss = 0.03700256
Iteration 695, loss = 0.03696052
Iteration 696, loss = 0.03680187
Iteration 697, loss = 0.03670454
Iteration 698, loss = 0.03662307
Iteration 699, loss = 0.03658247
Iteration 700, loss = 0.03659077
Iteration 701, loss = 0.03639779
Iteration 702, loss = 0.03657668
Iteration 703, loss = 0.03647146
Iteration 704, loss = 0.03642808
Iteration 705, loss = 0.03627246
Iteration 706, loss = 0.03610928
Iteration 707, loss = 0.03592513
Iteration 708, loss = 0.03589976
Iteration 709, loss = 0.03572359
Iteration 710, loss = 0.03560572
Iteration 711, loss = 0.03553603
Iteration 712, loss = 0.03545323
Iteration 713, loss = 0.03540985
Iteration 714, loss = 0.03532094
Iteration 715, loss = 0.03530546
Iteration 716, loss = 0.03520989
Iteration 717, loss = 0.03512794
Iteration 718, loss = 0.03498088
Iteration 719, loss = 0.03504477
Iteration 720, loss = 0.03480296
Iteration 721, loss = 0.03466134
Iteration 722, loss = 0.03473849
Iteration 723, loss = 0.03481755
Iteration 724, loss = 0.03486508
Iteration 725, loss = 0.03482436
Iteration 726, loss = 0.03473267
Iteration 727, loss = 0.03445836
Iteration 728, loss = 0.03424851
Iteration 729, loss = 0.03421951
Iteration 730, loss = 0.03413278
Iteration 731, loss = 0.03415349
Iteration 732, loss = 0.03410979
Iteration 733, loss = 0.03401214
Iteration 734, loss = 0.03386969
Iteration 735, loss = 0.03371111
Iteration 736, loss = 0.03363601
Iteration 737, loss = 0.03351026
Iteration 738, loss = 0.03345465
Iteration 739, loss = 0.03339940
Iteration 740, loss = 0.03336669
Iteration 741, loss = 0.03331487
Iteration 742, loss = 0.03327183
Iteration 743, loss = 0.03322203
Iteration 744, loss = 0.03318744
Iteration 745, loss = 0.03304382
Iteration 746, loss = 0.03300737
Iteration 747, loss = 0.03300169
Iteration 748, loss = 0.03296593
Iteration 749, loss = 0.03294011
Iteration 750, loss = 0.03289415
Iteration 751, loss = 0.03278877
Iteration 752, loss = 0.03275653
Iteration 753, loss = 0.03274422
Iteration 754, loss = 0.03268244
Iteration 755, loss = 0.03257448
Iteration 756, loss = 0.03251643
Iteration 757, loss = 0.03245024
Iteration 758, loss = 0.03239790
Iteration 759, loss = 0.03240361
Iteration 760, loss = 0.03262166
Iteration 761, loss = 0.03243796
Iteration 762, loss = 0.03221074
Iteration 763, loss = 0.03210196
Iteration 764, loss = 0.03182748
Iteration 765, loss = 0.03186907
Iteration 766, loss = 0.03174140
Iteration 767, loss = 0.03172304
Iteration 768, loss = 0.03152834
Iteration 769, loss = 0.03148462
Iteration 770, loss = 0.03134282
Iteration 771, loss = 0.03131551
Iteration 772, loss = 0.03124109
Iteration 773, loss = 0.03116534
Iteration 774, loss = 0.03112139
Iteration 775, loss = 0.03106356
Iteration 776, loss = 0.03101188
Iteration 777, loss = 0.03099157
Iteration 778, loss = 0.03104855
Iteration 779, loss = 0.03097994
Iteration 780, loss = 0.03092762
Iteration 781, loss = 0.03088307
Iteration 782, loss = 0.03073034
Iteration 783, loss = 0.03060858
Iteration 784, loss = 0.03050731
Iteration 785, loss = 0.03041443
Iteration 786, loss = 0.03036065
Iteration 787, loss = 0.03021274
Iteration 788, loss = 0.03011413
Iteration 789, loss = 0.03003549
Iteration 790, loss = 0.02995137
Iteration 791, loss = 0.02989819
Iteration 792, loss = 0.02988727
Iteration 793, loss = 0.02980990
Iteration 794, loss = 0.02975535
Iteration 795, loss = 0.02974517
Iteration 796, loss = 0.02976922
Iteration 797, loss = 0.02965980
Iteration 798, loss = 0.02963910
Iteration 799, loss = 0.02964776
Iteration 800, loss = 0.02963900
Iteration 801, loss = 0.02957263
Iteration 802, loss = 0.02951814
Iteration 803, loss = 0.02949151
Iteration 804, loss = 0.02939178
Iteration 805, loss = 0.02933866
Iteration 806, loss = 0.02927326
Iteration 807, loss = 0.02921241
Iteration 808, loss = 0.02919624
Iteration 809, loss = 0.02923358
Iteration 810, loss = 0.02906396
Iteration 811, loss = 0.02896994
Iteration 812, loss = 0.02889538
Iteration 813, loss = 0.02883677
Iteration 814, loss = 0.02865954
Iteration 815, loss = 0.02856575
Iteration 816, loss = 0.02848004
Iteration 817, loss = 0.02846786
Iteration 818, loss = 0.02836453
Iteration 819, loss = 0.02819475
Iteration 820, loss = 0.02814853
Iteration 821, loss = 0.02807717
Iteration 822, loss = 0.02806094
Iteration 823, loss = 0.02789471
Iteration 824, loss = 0.02788099
Iteration 825, loss = 0.02787885
Iteration 826, loss = 0.02788067
Iteration 827, loss = 0.02789136
Iteration 828, loss = 0.02791962
Iteration 829, loss = 0.02789804
Iteration 830, loss = 0.02788259
Iteration 831, loss = 0.02783274
Iteration 832, loss = 0.02777200
Iteration 833, loss = 0.02770735
Iteration 834, loss = 0.02763143
Iteration 835, loss = 0.02749373
Iteration 836, loss = 0.02768031
Iteration 837, loss = 0.02732584
Iteration 838, loss = 0.02724796
Iteration 839, loss = 0.02715241
Iteration 840, loss = 0.02708578
Iteration 841, loss = 0.02716123
Iteration 842, loss = 0.02703564
Iteration 843, loss = 0.02694496
Iteration 844, loss = 0.02693262
Iteration 845, loss = 0.02685644
Iteration 846, loss = 0.02680490
Iteration 847, loss = 0.02675315
Iteration 848, loss = 0.02672044
Iteration 849, loss = 0.02669126
Iteration 850, loss = 0.02657784
Iteration 851, loss = 0.02647922
Iteration 852, loss = 0.02632249
Iteration 853, loss = 0.02624659
Iteration 854, loss = 0.02639657
Iteration 855, loss = 0.02634241
Iteration 856, loss = 0.02633603
Iteration 857, loss = 0.02621801
Iteration 858, loss = 0.02604490
Iteration 859, loss = 0.02592345
Iteration 860, loss = 0.02600333
Iteration 861, loss = 0.02602311
Iteration 862, loss = 0.02588744
Iteration 863, loss = 0.02583004
Iteration 864, loss = 0.02577302
Iteration 865, loss = 0.02572799
Iteration 866, loss = 0.02563156
Iteration 867, loss = 0.02562664
Iteration 868, loss = 0.02548683
Iteration 869, loss = 0.02543024
Iteration 870, loss = 0.02551282
Iteration 871, loss = 0.02579943
Iteration 872, loss = 0.02577143
Iteration 873, loss = 0.02569329
Iteration 874, loss = 0.02542981
Iteration 875, loss = 0.02538972
Iteration 876, loss = 0.02512317
Iteration 877, loss = 0.02507311
Iteration 878, loss = 0.02500321
Iteration 879, loss = 0.02491375
Iteration 880, loss = 0.02489768
Iteration 881, loss = 0.02481375
Iteration 882, loss = 0.02477222
Iteration 883, loss = 0.02473108
Iteration 884, loss = 0.02465777
Iteration 885, loss = 0.02471339
Iteration 886, loss = 0.02467197
Iteration 887, loss = 0.02467138
Iteration 888, loss = 0.02465923
Iteration 889, loss = 0.02467461
Iteration 890, loss = 0.02476881
Iteration 891, loss = 0.02462675
Iteration 892, loss = 0.02449785
Iteration 893, loss = 0.02433945
Iteration 894, loss = 0.02425564
Iteration 895, loss = 0.02419063
Iteration 896, loss = 0.02416987
Iteration 897, loss = 0.02411401
Iteration 898, loss = 0.02406970
Iteration 899, loss = 0.02401934
Iteration 900, loss = 0.02407958
Iteration 901, loss = 0.02395388
Iteration 902, loss = 0.02381611
Iteration 903, loss = 0.02372029
Iteration 904, loss = 0.02371910
Iteration 905, loss = 0.02369428
Iteration 906, loss = 0.02369400
Iteration 907, loss = 0.02370399
Iteration 908, loss = 0.02364354
Iteration 909, loss = 0.02349581
Iteration 910, loss = 0.02342174
Iteration 911, loss = 0.02332970
Iteration 912, loss = 0.02329252
Iteration 913, loss = 0.02344421
Iteration 914, loss = 0.02331387
Iteration 915, loss = 0.02319912
Iteration 916, loss = 0.02310748
Iteration 917, loss = 0.02316608
Iteration 918, loss = 0.02305576
Iteration 919, loss = 0.02306634
Iteration 920, loss = 0.02299876
Iteration 921, loss = 0.02295543
Iteration 922, loss = 0.02289627
Iteration 923, loss = 0.02290376
Iteration 924, loss = 0.02282301
Iteration 925, loss = 0.02278069
Iteration 926, loss = 0.02276740
Iteration 927, loss = 0.02269339
Iteration 928, loss = 0.02264456
Iteration 929, loss = 0.02260384
Iteration 930, loss = 0.02259342
Iteration 931, loss = 0.02245781
Iteration 932, loss = 0.02242889
Iteration 933, loss = 0.02254816
Iteration 934, loss = 0.02244010
Iteration 935, loss = 0.02233395
Iteration 936, loss = 0.02226586
Iteration 937, loss = 0.02222872
Iteration 938, loss = 0.02214191
Iteration 939, loss = 0.02208319
Iteration 940, loss = 0.02208237
Iteration 941, loss = 0.02203879
Iteration 942, loss = 0.02203971
Iteration 943, loss = 0.02198131
Iteration 944, loss = 0.02200261
Iteration 945, loss = 0.02206002
Iteration 946, loss = 0.02213806
Iteration 947, loss = 0.02211207
Iteration 948, loss = 0.02204731
Iteration 949, loss = 0.02200210
Iteration 950, loss = 0.02186194
Iteration 951, loss = 0.02168900
Iteration 952, loss = 0.02154025
Iteration 953, loss = 0.02152521
Iteration 954, loss = 0.02153951
Iteration 955, loss = 0.02155545
Iteration 956, loss = 0.02149286
Iteration 957, loss = 0.02141356
Iteration 958, loss = 0.02134974
Iteration 959, loss = 0.02126346
Iteration 960, loss = 0.02116507
Iteration 961, loss = 0.02129929
Iteration 962, loss = 0.02126160
Iteration 963, loss = 0.02124777
Iteration 964, loss = 0.02120908
Iteration 965, loss = 0.02117188
Iteration 966, loss = 0.02111881
Iteration 967, loss = 0.02102469
Iteration 968, loss = 0.02098593
Iteration 969, loss = 0.02088551
Iteration 970, loss = 0.02081915
Iteration 971, loss = 0.02077416
Iteration 972, loss = 0.02071592
Iteration 973, loss = 0.02071183
Iteration 974, loss = 0.02064962
Iteration 975, loss = 0.02060811
Iteration 976, loss = 0.02055686
Iteration 977, loss = 0.02053315
Iteration 978, loss = 0.02052456
Iteration 979, loss = 0.02060497
Iteration 980, loss = 0.02047573
Iteration 981, loss = 0.02040315
Iteration 982, loss = 0.02034392
Iteration 983, loss = 0.02036974
Iteration 984, loss = 0.02053450
Iteration 985, loss = 0.02039451
Iteration 986, loss = 0.02020706
Iteration 987, loss = 0.02018251
Iteration 988, loss = 0.02012515
Iteration 989, loss = 0.02008962
Iteration 990, loss = 0.02007101
Iteration 991, loss = 0.02000045
Iteration 992, loss = 0.01995252
Iteration 993, loss = 0.01992626
Iteration 994, loss = 0.01994554
Iteration 995, loss = 0.01997830
Iteration 996, loss = 0.02007910
Iteration 997, loss = 0.02000020
Iteration 998, loss = 0.01983968
Iteration 999, loss = 0.01973345
Iteration 1000, loss = 0.01972964
PARAMETROS DE INICIALIZACAO DA REDE
NUMERO DE NEURONIOS 
Camada de Entrada: 34
Camada Escondida: 3
Camada de Saida: 1

--- PARAMETROS DE CONFIGURACAO DA REDE ---
Numero de Epocas: 1000
Taxa de Aprendizado: adaptive
Taxa de Aprendizado Inicial: 0.1
METRICAS

RESULTADOS:

[0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1
 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1
 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 0]
ACURACIA: 0.9245283018867925

