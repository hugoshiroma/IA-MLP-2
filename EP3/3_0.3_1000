Pesos Camada de Entrada: 
[[ 0.0484629  -0.17130237 -0.07932525]
 [-0.05898464  0.0054965  -0.18508068]
 [-0.01712995 -0.11319212  0.02272598]
 [-0.00196225  0.00827818  0.22526954]
 [-0.06350765  0.18525037  0.12226649]
 [-0.19226547 -0.15693366 -0.01524246]
 [-0.21613444 -0.0785646  -0.02870098]
 [ 0.12289954  0.08526814  0.03867496]
 [-0.03884882  0.20679847 -0.11240306]
 [-0.06509146 -0.08722143 -0.1655665 ]
 [-0.07909612  0.03185851 -0.15241828]
 [-0.09388278  0.1376861  -0.08758015]
 [ 0.11473859 -0.12516441 -0.01017671]
 [ 0.03897482  0.12563214 -0.08211964]
 [-0.15761464 -0.17756183  0.13320932]
 [-0.12252699 -0.10151788 -0.00773726]
 [-0.13214105 -0.03622906  0.10256632]
 [ 0.14918945  0.19761233 -0.16309775]
 [-0.00620494  0.19114216 -0.06045243]
 [ 0.03572398 -0.07626711 -0.11626505]
 [ 0.09568839  0.01081333  0.08817427]
 [ 0.0163249  -0.10611073  0.13296927]
 [ 0.13466404  0.00639211  0.0762211 ]
 [-0.19437842 -0.08483162  0.13220901]
 [ 0.22389962  0.01208974  0.15634443]
 [-0.15540896  0.05952426 -0.02227908]
 [ 0.1090146  -0.0760402   0.10653835]
 [ 0.20841237  0.11811575  0.11368383]
 [-0.16877461 -0.19439547 -0.10103647]
 [ 0.20459051 -0.21760842  0.21020437]
 [-0.07257091 -0.02739002  0.17598567]
 [-0.00474556  0.06936928 -0.16462905]
 [ 0.09482755 -0.06957429 -0.06503734]
 [ 0.03178294 -0.03791647 -0.223148  ]]
Bias Camada de Entrada: 
[ 0.19249922 -0.16754403  0.01287446]
Pesos Camada Escondida: 
[[-0.55385046]
 [ 0.59599735]
 [ 0.58980714]]
Bias Camada Escondida: 
[0.25608872]
Iteration 1, loss = 0.64940662
Iteration 2, loss = 0.64007309
Iteration 3, loss = 0.62958886
Iteration 4, loss = 0.61744660
Iteration 5, loss = 0.59558975
Iteration 6, loss = 0.57417781
Iteration 7, loss = 0.55247662
Iteration 8, loss = 0.53148482
Iteration 9, loss = 0.50695698
Iteration 10, loss = 0.47999150
Iteration 11, loss = 0.45732722
Iteration 12, loss = 0.43655084
Iteration 13, loss = 0.41540636
Iteration 14, loss = 0.39331200
Iteration 15, loss = 0.37364032
Iteration 16, loss = 0.35819443
Iteration 17, loss = 0.34522511
Iteration 18, loss = 0.33231482
Iteration 19, loss = 0.32211887
Iteration 20, loss = 0.31287843
Iteration 21, loss = 0.30654007
Iteration 22, loss = 0.30249702
Iteration 23, loss = 0.29492566
Iteration 24, loss = 0.28860105
Iteration 25, loss = 0.28566006
Iteration 26, loss = 0.27775966
Iteration 27, loss = 0.27022194
Iteration 28, loss = 0.26553054
Iteration 29, loss = 0.25874326
Iteration 30, loss = 0.25560902
Iteration 31, loss = 0.25158509
Iteration 32, loss = 0.24488304
Iteration 33, loss = 0.24033370
Iteration 34, loss = 0.23823722
Iteration 35, loss = 0.23573746
Iteration 36, loss = 0.23245086
Iteration 37, loss = 0.22613222
Iteration 38, loss = 0.22146319
Iteration 39, loss = 0.21942906
Iteration 40, loss = 0.21529852
Iteration 41, loss = 0.21194740
Iteration 42, loss = 0.20986854
Iteration 43, loss = 0.20604892
Iteration 44, loss = 0.20366192
Iteration 45, loss = 0.20212283
Iteration 46, loss = 0.19665950
Iteration 47, loss = 0.19542744
Iteration 48, loss = 0.19650897
Iteration 49, loss = 0.18786043
Iteration 50, loss = 0.18819235
Iteration 51, loss = 0.18532804
Iteration 52, loss = 0.17858158
Iteration 53, loss = 0.17586354
Iteration 54, loss = 0.17698193
Iteration 55, loss = 0.17365361
Iteration 56, loss = 0.16766443
Iteration 57, loss = 0.16644682
Iteration 58, loss = 0.17031192
Iteration 59, loss = 0.16601820
Iteration 60, loss = 0.15661240
Iteration 61, loss = 0.15727858
Iteration 62, loss = 0.15386039
Iteration 63, loss = 0.15145529
Iteration 64, loss = 0.14925127
Iteration 65, loss = 0.14780688
Iteration 66, loss = 0.14525228
Iteration 67, loss = 0.14159879
Iteration 68, loss = 0.14130510
Iteration 69, loss = 0.13927321
Iteration 70, loss = 0.13612585
Iteration 71, loss = 0.13347869
Iteration 72, loss = 0.13198057
Iteration 73, loss = 0.13023008
Iteration 74, loss = 0.12864816
Iteration 75, loss = 0.12688099
Iteration 76, loss = 0.12573063
Iteration 77, loss = 0.12331216
Iteration 78, loss = 0.12211262
Iteration 79, loss = 0.12060147
Iteration 80, loss = 0.11891302
Iteration 81, loss = 0.11756022
Iteration 82, loss = 0.11605246
Iteration 83, loss = 0.11426739
Iteration 84, loss = 0.11320249
Iteration 85, loss = 0.11181945
Iteration 86, loss = 0.11163522
Iteration 87, loss = 0.11097061
Iteration 88, loss = 0.10692936
Iteration 89, loss = 0.10707469
Iteration 90, loss = 0.10542361
Iteration 91, loss = 0.10417001
Iteration 92, loss = 0.10274444
Iteration 93, loss = 0.10164933
Iteration 94, loss = 0.10071547
Iteration 95, loss = 0.09981126
Iteration 96, loss = 0.09889907
Iteration 97, loss = 0.09761951
Iteration 98, loss = 0.09818390
Iteration 99, loss = 0.09831883
Iteration 100, loss = 0.09605829
Iteration 101, loss = 0.09388178
Iteration 102, loss = 0.09351210
Iteration 103, loss = 0.09349268
Iteration 104, loss = 0.09130362
Iteration 105, loss = 0.08974976
Iteration 106, loss = 0.08906675
Iteration 107, loss = 0.08846557
Iteration 108, loss = 0.08789573
Iteration 109, loss = 0.08679566
Iteration 110, loss = 0.08559761
Iteration 111, loss = 0.08515725
Iteration 112, loss = 0.08401840
Iteration 113, loss = 0.08339666
Iteration 114, loss = 0.08236558
Iteration 115, loss = 0.08226696
Iteration 116, loss = 0.08122500
Iteration 117, loss = 0.08061279
Iteration 118, loss = 0.08103316
Iteration 119, loss = 0.08057171
Iteration 120, loss = 0.07946675
Iteration 121, loss = 0.07767043
Iteration 122, loss = 0.07686006
Iteration 123, loss = 0.07719774
Iteration 124, loss = 0.07970405
Iteration 125, loss = 0.07874264
Iteration 126, loss = 0.07636103
Iteration 127, loss = 0.07311338
Iteration 128, loss = 0.07159703
Iteration 129, loss = 0.07156748
Iteration 130, loss = 0.07179788
Iteration 131, loss = 0.07060785
Iteration 132, loss = 0.06993433
Iteration 133, loss = 0.06883840
Iteration 134, loss = 0.06786851
Iteration 135, loss = 0.06684410
Iteration 136, loss = 0.06670757
Iteration 137, loss = 0.06616987
Iteration 138, loss = 0.06643590
Iteration 139, loss = 0.06581541
Iteration 140, loss = 0.06544771
Iteration 141, loss = 0.06502725
Iteration 142, loss = 0.06415097
Iteration 143, loss = 0.06294601
Iteration 144, loss = 0.06201003
Iteration 145, loss = 0.06174478
Iteration 146, loss = 0.06140975
Iteration 147, loss = 0.06124798
Iteration 148, loss = 0.06101827
Iteration 149, loss = 0.06050361
Iteration 150, loss = 0.05992579
Iteration 151, loss = 0.05878118
Iteration 152, loss = 0.05809811
Iteration 153, loss = 0.05778765
Iteration 154, loss = 0.05777897
Iteration 155, loss = 0.05775304
Iteration 156, loss = 0.05744810
Iteration 157, loss = 0.05670001
Iteration 158, loss = 0.05606348
Iteration 159, loss = 0.05553137
Iteration 160, loss = 0.05533113
Iteration 161, loss = 0.05535209
Iteration 162, loss = 0.05490115
Iteration 163, loss = 0.05454663
Iteration 164, loss = 0.05339652
Iteration 165, loss = 0.05374539
Iteration 166, loss = 0.05374292
Iteration 167, loss = 0.05364641
Iteration 168, loss = 0.05310984
Iteration 169, loss = 0.05289807
Iteration 170, loss = 0.05271991
Iteration 171, loss = 0.05244078
Iteration 172, loss = 0.05139863
Iteration 173, loss = 0.05109555
Iteration 174, loss = 0.05088841
Iteration 175, loss = 0.05044841
Iteration 176, loss = 0.05027541
Iteration 177, loss = 0.04998010
Iteration 178, loss = 0.04967076
Iteration 179, loss = 0.04962294
Iteration 180, loss = 0.04949989
Iteration 181, loss = 0.04950052
Iteration 182, loss = 0.04943628
Iteration 183, loss = 0.04870337
Iteration 184, loss = 0.04823883
Iteration 185, loss = 0.04778119
Iteration 186, loss = 0.04750432
Iteration 187, loss = 0.04729513
Iteration 188, loss = 0.04704102
Iteration 189, loss = 0.04737300
Iteration 190, loss = 0.04655559
Iteration 191, loss = 0.04637364
Iteration 192, loss = 0.04620760
Iteration 193, loss = 0.04561141
Iteration 194, loss = 0.04570043
Iteration 195, loss = 0.04555854
Iteration 196, loss = 0.04579992
Iteration 197, loss = 0.04555289
Iteration 198, loss = 0.04502836
Iteration 199, loss = 0.04447672
Iteration 200, loss = 0.04403535
Iteration 201, loss = 0.04403112
Iteration 202, loss = 0.04407434
Iteration 203, loss = 0.04410656
Iteration 204, loss = 0.04415299
Iteration 205, loss = 0.04395070
Iteration 206, loss = 0.04308887
Iteration 207, loss = 0.04271390
Iteration 208, loss = 0.04260165
Iteration 209, loss = 0.04251807
Iteration 210, loss = 0.04239380
Iteration 211, loss = 0.04227254
Iteration 212, loss = 0.04203107
Iteration 213, loss = 0.04164615
Iteration 214, loss = 0.04137887
Iteration 215, loss = 0.04127702
Iteration 216, loss = 0.04119397
Iteration 217, loss = 0.04090304
Iteration 218, loss = 0.04070730
Iteration 219, loss = 0.04061063
Iteration 220, loss = 0.04052315
Iteration 221, loss = 0.04034813
Iteration 222, loss = 0.04020065
Iteration 223, loss = 0.04004121
Iteration 224, loss = 0.03974680
Iteration 225, loss = 0.03955133
Iteration 226, loss = 0.03960091
Iteration 227, loss = 0.03955621
Iteration 228, loss = 0.03952740
Iteration 229, loss = 0.03911708
Iteration 230, loss = 0.03871032
Iteration 231, loss = 0.03872480
Iteration 232, loss = 0.03932604
Iteration 233, loss = 0.04007553
Iteration 234, loss = 0.03958894
Iteration 235, loss = 0.03846685
Iteration 236, loss = 0.03803130
Iteration 237, loss = 0.03783056
Iteration 238, loss = 0.03862113
Iteration 239, loss = 0.03725694
Iteration 240, loss = 0.03767738
Iteration 241, loss = 0.03764540
Iteration 242, loss = 0.03757779
Iteration 243, loss = 0.03711870
Iteration 244, loss = 0.03687351
Iteration 245, loss = 0.03655356
Iteration 246, loss = 0.03641788
Iteration 247, loss = 0.03621829
Iteration 248, loss = 0.03603386
Iteration 249, loss = 0.03584907
Iteration 250, loss = 0.03568889
Iteration 251, loss = 0.03561783
Iteration 252, loss = 0.03556341
Iteration 253, loss = 0.03556650
Iteration 254, loss = 0.03559446
Iteration 255, loss = 0.03536995
Iteration 256, loss = 0.03542139
Iteration 257, loss = 0.03535686
Iteration 258, loss = 0.03511233
Iteration 259, loss = 0.03511964
Iteration 260, loss = 0.03464663
Iteration 261, loss = 0.03458811
Iteration 262, loss = 0.03423479
Iteration 263, loss = 0.03418743
Iteration 264, loss = 0.03416696
Iteration 265, loss = 0.03411378
Iteration 266, loss = 0.03402941
Iteration 267, loss = 0.03383483
Iteration 268, loss = 0.03378936
Iteration 269, loss = 0.03379531
Iteration 270, loss = 0.03364299
Iteration 271, loss = 0.03349022
Iteration 272, loss = 0.03337837
Iteration 273, loss = 0.03320747
Iteration 274, loss = 0.03344207
Iteration 275, loss = 0.03310237
Iteration 276, loss = 0.03302883
Iteration 277, loss = 0.03294673
Iteration 278, loss = 0.03280610
Iteration 279, loss = 0.03263475
Iteration 280, loss = 0.03245618
Iteration 281, loss = 0.03248103
Iteration 282, loss = 0.03260585
Iteration 283, loss = 0.03239074
Iteration 284, loss = 0.03231630
Iteration 285, loss = 0.03236605
Iteration 286, loss = 0.03209509
Iteration 287, loss = 0.03183815
Iteration 288, loss = 0.03163355
Iteration 289, loss = 0.03159111
Iteration 290, loss = 0.03129933
Iteration 291, loss = 0.03147660
Iteration 292, loss = 0.03102909
Iteration 293, loss = 0.03084278
Iteration 294, loss = 0.03087235
Iteration 295, loss = 0.03073412
Iteration 296, loss = 0.03073578
Iteration 297, loss = 0.03071251
Iteration 298, loss = 0.03079622
Iteration 299, loss = 0.03068335
Iteration 300, loss = 0.03042824
Iteration 301, loss = 0.03029975
Iteration 302, loss = 0.03022230
Iteration 303, loss = 0.03026207
Iteration 304, loss = 0.03031778
Iteration 305, loss = 0.03025774
Iteration 306, loss = 0.02975739
Iteration 307, loss = 0.02977591
Iteration 308, loss = 0.02995236
Iteration 309, loss = 0.02981907
Iteration 310, loss = 0.02950416
Iteration 311, loss = 0.02940482
Iteration 312, loss = 0.02946699
Iteration 313, loss = 0.02974139
Iteration 314, loss = 0.02980872
Iteration 315, loss = 0.02953933
Iteration 316, loss = 0.02943021
Iteration 317, loss = 0.02925169
Iteration 318, loss = 0.02922929
Iteration 319, loss = 0.02953868
Iteration 320, loss = 0.02884991
Iteration 321, loss = 0.02854274
Iteration 322, loss = 0.02833162
Iteration 323, loss = 0.02840782
Iteration 324, loss = 0.02861448
Iteration 325, loss = 0.02852486
Iteration 326, loss = 0.02826288
Iteration 327, loss = 0.02819580
Iteration 328, loss = 0.02827047
Iteration 329, loss = 0.02813411
Iteration 330, loss = 0.02788466
Iteration 331, loss = 0.02780542
Iteration 332, loss = 0.02781248
Iteration 333, loss = 0.02791880
Iteration 334, loss = 0.02762907
Iteration 335, loss = 0.02761544
Iteration 336, loss = 0.02769356
Iteration 337, loss = 0.02740729
Iteration 338, loss = 0.02726468
Iteration 339, loss = 0.02727033
Iteration 340, loss = 0.02713405
Iteration 341, loss = 0.02708314
Iteration 342, loss = 0.02693440
Iteration 343, loss = 0.02690388
Iteration 344, loss = 0.02679944
Iteration 345, loss = 0.02680533
Iteration 346, loss = 0.02675438
Iteration 347, loss = 0.02654983
Iteration 348, loss = 0.02693231
Iteration 349, loss = 0.02646659
Iteration 350, loss = 0.02631138
Iteration 351, loss = 0.02622610
Iteration 352, loss = 0.02622643
Iteration 353, loss = 0.02621128
Iteration 354, loss = 0.02630341
Iteration 355, loss = 0.02611817
Iteration 356, loss = 0.02603819
Iteration 357, loss = 0.02598515
Iteration 358, loss = 0.02595521
Iteration 359, loss = 0.02588176
Iteration 360, loss = 0.02578822
Iteration 361, loss = 0.02566597
Iteration 362, loss = 0.02550325
Iteration 363, loss = 0.02558013
Iteration 364, loss = 0.02546237
Iteration 365, loss = 0.02543397
Iteration 366, loss = 0.02548798
Iteration 367, loss = 0.02555465
Iteration 368, loss = 0.02558804
Iteration 369, loss = 0.02556990
Iteration 370, loss = 0.02520273
Iteration 371, loss = 0.02498970
Iteration 372, loss = 0.02489748
Iteration 373, loss = 0.02487344
Iteration 374, loss = 0.02510815
Iteration 375, loss = 0.02475763
Iteration 376, loss = 0.02452544
Iteration 377, loss = 0.02444775
Iteration 378, loss = 0.02485644
Iteration 379, loss = 0.02514357
Iteration 380, loss = 0.02511796
Iteration 381, loss = 0.02488010
Iteration 382, loss = 0.02452188
Iteration 383, loss = 0.02423658
Iteration 384, loss = 0.02414948
Iteration 385, loss = 0.02429092
Iteration 386, loss = 0.02458595
Iteration 387, loss = 0.02397076
Iteration 388, loss = 0.02391635
Iteration 389, loss = 0.02386657
Iteration 390, loss = 0.02380465
Iteration 391, loss = 0.02375112
Iteration 392, loss = 0.02371646
Iteration 393, loss = 0.02360939
Iteration 394, loss = 0.02362220
Iteration 395, loss = 0.02369436
Iteration 396, loss = 0.02353731
Iteration 397, loss = 0.02330658
Iteration 398, loss = 0.02341743
Iteration 399, loss = 0.02346235
Iteration 400, loss = 0.02343096
Iteration 401, loss = 0.02339393
Iteration 402, loss = 0.02323575
Iteration 403, loss = 0.02315431
Iteration 404, loss = 0.02305036
Iteration 405, loss = 0.02288738
Iteration 406, loss = 0.02273827
Iteration 407, loss = 0.02263200
Iteration 408, loss = 0.02259119
Iteration 409, loss = 0.02260147
Iteration 410, loss = 0.02258041
Iteration 411, loss = 0.02260596
Iteration 412, loss = 0.02241343
Iteration 413, loss = 0.02234684
Iteration 414, loss = 0.02223818
Iteration 415, loss = 0.02227723
Iteration 416, loss = 0.02213606
Iteration 417, loss = 0.02203096
Iteration 418, loss = 0.02198063
Iteration 419, loss = 0.02196663
Iteration 420, loss = 0.02189798
Iteration 421, loss = 0.02183245
Iteration 422, loss = 0.02180930
Iteration 423, loss = 0.02183809
Iteration 424, loss = 0.02193475
Iteration 425, loss = 0.02189496
Iteration 426, loss = 0.02169975
Iteration 427, loss = 0.02153365
Iteration 428, loss = 0.02176683
Iteration 429, loss = 0.02207610
Iteration 430, loss = 0.02224299
Iteration 431, loss = 0.02202033
Iteration 432, loss = 0.02174885
Iteration 433, loss = 0.02145739
Iteration 434, loss = 0.02129689
Iteration 435, loss = 0.02118151
Iteration 436, loss = 0.02111420
Iteration 437, loss = 0.02117862
Iteration 438, loss = 0.02132784
Iteration 439, loss = 0.02096847
Iteration 440, loss = 0.02082762
Iteration 441, loss = 0.02077772
Iteration 442, loss = 0.02083259
Iteration 443, loss = 0.02075379
Iteration 444, loss = 0.02077153
Iteration 445, loss = 0.02081107
Iteration 446, loss = 0.02064107
Iteration 447, loss = 0.02047609
Iteration 448, loss = 0.02036678
Iteration 449, loss = 0.02044679
Iteration 450, loss = 0.02046936
Iteration 451, loss = 0.02040900
Iteration 452, loss = 0.02037933
Iteration 453, loss = 0.02032072
Iteration 454, loss = 0.02025833
Iteration 455, loss = 0.02017264
Iteration 456, loss = 0.02007612
Iteration 457, loss = 0.02010297
Iteration 458, loss = 0.01998744
Iteration 459, loss = 0.01992221
Iteration 460, loss = 0.01998964
Iteration 461, loss = 0.01988904
Iteration 462, loss = 0.01981725
Iteration 463, loss = 0.01975540
Iteration 464, loss = 0.01973860
Iteration 465, loss = 0.01975599
Iteration 466, loss = 0.01983603
Iteration 467, loss = 0.02002735
Iteration 468, loss = 0.01978499
Iteration 469, loss = 0.01957101
Iteration 470, loss = 0.01937160
Iteration 471, loss = 0.01931205
Iteration 472, loss = 0.01925050
Iteration 473, loss = 0.01920174
Iteration 474, loss = 0.01920903
Iteration 475, loss = 0.01919651
Iteration 476, loss = 0.01921756
Iteration 477, loss = 0.01922914
Iteration 478, loss = 0.01922638
Iteration 479, loss = 0.01919840
Iteration 480, loss = 0.01915809
Iteration 481, loss = 0.01914394
Iteration 482, loss = 0.01907943
Iteration 483, loss = 0.01904564
Iteration 484, loss = 0.01890644
Iteration 485, loss = 0.01887451
Iteration 486, loss = 0.01882568
Iteration 487, loss = 0.01873971
Iteration 488, loss = 0.01868049
Iteration 489, loss = 0.01862943
Iteration 490, loss = 0.01860148
Iteration 491, loss = 0.01855206
Iteration 492, loss = 0.01859897
Iteration 493, loss = 0.01864901
Iteration 494, loss = 0.01856436
Iteration 495, loss = 0.01845086
Iteration 496, loss = 0.01841050
Iteration 497, loss = 0.01832896
Iteration 498, loss = 0.01830692
Iteration 499, loss = 0.01826471
Iteration 500, loss = 0.01819106
Iteration 501, loss = 0.01805052
Iteration 502, loss = 0.01812417
Iteration 503, loss = 0.01808987
Iteration 504, loss = 0.01807972
Iteration 505, loss = 0.01812772
Iteration 506, loss = 0.01795214
Iteration 507, loss = 0.01782108
Iteration 508, loss = 0.01776508
Iteration 509, loss = 0.01774982
Iteration 510, loss = 0.01770422
Iteration 511, loss = 0.01768508
Iteration 512, loss = 0.01769863
Iteration 513, loss = 0.01744109
Iteration 514, loss = 0.01737458
Iteration 515, loss = 0.01736961
Iteration 516, loss = 0.01731568
Iteration 517, loss = 0.01725629
Iteration 518, loss = 0.01721084
Iteration 519, loss = 0.01715123
Iteration 520, loss = 0.01715014
Iteration 521, loss = 0.01714818
Iteration 522, loss = 0.01711775
Iteration 523, loss = 0.01705525
Iteration 524, loss = 0.01716227
Iteration 525, loss = 0.01699460
Iteration 526, loss = 0.01689236
Iteration 527, loss = 0.01678937
Iteration 528, loss = 0.01672983
Iteration 529, loss = 0.01670667
Iteration 530, loss = 0.01672158
Iteration 531, loss = 0.01675309
Iteration 532, loss = 0.01661303
Iteration 533, loss = 0.01655006
Iteration 534, loss = 0.01651343
Iteration 535, loss = 0.01661403
Iteration 536, loss = 0.01649900
Iteration 537, loss = 0.01644882
Iteration 538, loss = 0.01640479
Iteration 539, loss = 0.01640036
Iteration 540, loss = 0.01629266
Iteration 541, loss = 0.01624698
Iteration 542, loss = 0.01621921
Iteration 543, loss = 0.01617383
Iteration 544, loss = 0.01622755
Iteration 545, loss = 0.01622439
Iteration 546, loss = 0.01621137
Iteration 547, loss = 0.01624626
Iteration 548, loss = 0.01624253
Iteration 549, loss = 0.01621809
Iteration 550, loss = 0.01614621
Iteration 551, loss = 0.01605062
Iteration 552, loss = 0.01601972
Iteration 553, loss = 0.01595609
Iteration 554, loss = 0.01591173
Iteration 555, loss = 0.01586446
Iteration 556, loss = 0.01586428
Iteration 557, loss = 0.01584326
Iteration 558, loss = 0.01574245
Iteration 559, loss = 0.01567502
Iteration 560, loss = 0.01565526
Iteration 561, loss = 0.01558145
Iteration 562, loss = 0.01554701
Iteration 563, loss = 0.01548551
Iteration 564, loss = 0.01542054
Iteration 565, loss = 0.01544405
Iteration 566, loss = 0.01550950
Iteration 567, loss = 0.01551482
Iteration 568, loss = 0.01550828
Iteration 569, loss = 0.01542074
Iteration 570, loss = 0.01539940
Iteration 571, loss = 0.01530144
Iteration 572, loss = 0.01528106
Iteration 573, loss = 0.01523753
Iteration 574, loss = 0.01519542
Iteration 575, loss = 0.01514178
Iteration 576, loss = 0.01511794
Iteration 577, loss = 0.01509544
Iteration 578, loss = 0.01506986
Iteration 579, loss = 0.01502828
Iteration 580, loss = 0.01499384
Iteration 581, loss = 0.01498464
Iteration 582, loss = 0.01498434
Iteration 583, loss = 0.01498029
Iteration 584, loss = 0.01489231
Iteration 585, loss = 0.01480239
Iteration 586, loss = 0.01481824
Iteration 587, loss = 0.01505226
Iteration 588, loss = 0.01502626
Iteration 589, loss = 0.01483782
Iteration 590, loss = 0.01466630
Iteration 591, loss = 0.01471257
Iteration 592, loss = 0.01458480
Iteration 593, loss = 0.01456353
Iteration 594, loss = 0.01443378
Iteration 595, loss = 0.01440375
Iteration 596, loss = 0.01434824
Iteration 597, loss = 0.01432432
Iteration 598, loss = 0.01432058
Iteration 599, loss = 0.01429226
Iteration 600, loss = 0.01428867
Iteration 601, loss = 0.01431289
Iteration 602, loss = 0.01434527
Iteration 603, loss = 0.01430255
Iteration 604, loss = 0.01425335
Iteration 605, loss = 0.01420393
Iteration 606, loss = 0.01422818
Iteration 607, loss = 0.01415282
Iteration 608, loss = 0.01405459
Iteration 609, loss = 0.01406196
Iteration 610, loss = 0.01410046
Iteration 611, loss = 0.01404653
Iteration 612, loss = 0.01401933
Iteration 613, loss = 0.01399745
Iteration 614, loss = 0.01399126
Iteration 615, loss = 0.01388920
Iteration 616, loss = 0.01384343
Iteration 617, loss = 0.01386926
Iteration 618, loss = 0.01384058
Iteration 619, loss = 0.01383545
Iteration 620, loss = 0.01381695
Iteration 621, loss = 0.01376199
Iteration 622, loss = 0.01370658
Iteration 623, loss = 0.01365563
Iteration 624, loss = 0.01363336
Iteration 625, loss = 0.01360016
Iteration 626, loss = 0.01364575
Iteration 627, loss = 0.01371545
Iteration 628, loss = 0.01351412
Iteration 629, loss = 0.01345060
Iteration 630, loss = 0.01340517
Iteration 631, loss = 0.01337485
Iteration 632, loss = 0.01335552
Iteration 633, loss = 0.01335955
Iteration 634, loss = 0.01332163
Iteration 635, loss = 0.01328146
Iteration 636, loss = 0.01329632
Iteration 637, loss = 0.01323119
Iteration 638, loss = 0.01321986
Iteration 639, loss = 0.01321592
Iteration 640, loss = 0.01321588
Iteration 641, loss = 0.01321603
Iteration 642, loss = 0.01320466
Iteration 643, loss = 0.01319685
Iteration 644, loss = 0.01313415
Iteration 645, loss = 0.01308350
Iteration 646, loss = 0.01309146
Iteration 647, loss = 0.01307891
Iteration 648, loss = 0.01309293
Iteration 649, loss = 0.01307949
Iteration 650, loss = 0.01304519
Iteration 651, loss = 0.01299862
Iteration 652, loss = 0.01290107
Iteration 653, loss = 0.01282841
Iteration 654, loss = 0.01285320
Iteration 655, loss = 0.01276347
Iteration 656, loss = 0.01273068
Iteration 657, loss = 0.01270476
Iteration 658, loss = 0.01271003
Iteration 659, loss = 0.01270342
Iteration 660, loss = 0.01271963
Iteration 661, loss = 0.01282013
Iteration 662, loss = 0.01280442
Iteration 663, loss = 0.01268713
Iteration 664, loss = 0.01256240
Iteration 665, loss = 0.01252883
Iteration 666, loss = 0.01246987
Iteration 667, loss = 0.01252591
Iteration 668, loss = 0.01242628
Iteration 669, loss = 0.01240852
Iteration 670, loss = 0.01242983
Iteration 671, loss = 0.01239985
Iteration 672, loss = 0.01240331
Iteration 673, loss = 0.01237798
Iteration 674, loss = 0.01231027
Iteration 675, loss = 0.01229112
Iteration 676, loss = 0.01225140
Iteration 677, loss = 0.01221862
Iteration 678, loss = 0.01218471
Iteration 679, loss = 0.01215990
Iteration 680, loss = 0.01217062
Iteration 681, loss = 0.01211752
Iteration 682, loss = 0.01206978
Iteration 683, loss = 0.01204695
Iteration 684, loss = 0.01205599
Iteration 685, loss = 0.01206841
Iteration 686, loss = 0.01207773
Iteration 687, loss = 0.01209032
Iteration 688, loss = 0.01212332
Iteration 689, loss = 0.01195619
Iteration 690, loss = 0.01183705
Iteration 691, loss = 0.01191295
Iteration 692, loss = 0.01202162
Iteration 693, loss = 0.01224532
Iteration 694, loss = 0.01233419
Iteration 695, loss = 0.01227513
Iteration 696, loss = 0.01215076
Iteration 697, loss = 0.01198576
Iteration 698, loss = 0.01178932
Iteration 699, loss = 0.01174147
Iteration 700, loss = 0.01162555
Iteration 701, loss = 0.01160105
Iteration 702, loss = 0.01158442
Iteration 703, loss = 0.01158271
Iteration 704, loss = 0.01156008
Iteration 705, loss = 0.01154202
Iteration 706, loss = 0.01151928
Iteration 707, loss = 0.01151498
Iteration 708, loss = 0.01149906
Iteration 709, loss = 0.01149772
Iteration 710, loss = 0.01153920
Iteration 711, loss = 0.01145942
Iteration 712, loss = 0.01140674
Iteration 713, loss = 0.01136593
Iteration 714, loss = 0.01135797
Iteration 715, loss = 0.01136938
Iteration 716, loss = 0.01139665
Iteration 717, loss = 0.01136072
Iteration 718, loss = 0.01140552
Iteration 719, loss = 0.01130626
Iteration 720, loss = 0.01123152
Iteration 721, loss = 0.01121425
Iteration 722, loss = 0.01114800
Iteration 723, loss = 0.01112393
Iteration 724, loss = 0.01110874
Iteration 725, loss = 0.01109369
Iteration 726, loss = 0.01107722
Iteration 727, loss = 0.01105627
Iteration 728, loss = 0.01108723
Iteration 729, loss = 0.01107675
Iteration 730, loss = 0.01107885
Iteration 731, loss = 0.01107781
Iteration 732, loss = 0.01107575
Iteration 733, loss = 0.01102745
Iteration 734, loss = 0.01097844
Iteration 735, loss = 0.01097623
Iteration 736, loss = 0.01094120
Iteration 737, loss = 0.01091864
Iteration 738, loss = 0.01090768
Iteration 739, loss = 0.01089882
Iteration 740, loss = 0.01088996
Iteration 741, loss = 0.01086241
Iteration 742, loss = 0.01086040
Iteration 743, loss = 0.01083054
Iteration 744, loss = 0.01077940
Iteration 745, loss = 0.01072914
Iteration 746, loss = 0.01072762
Iteration 747, loss = 0.01072962
Iteration 748, loss = 0.01067191
Iteration 749, loss = 0.01066293
Iteration 750, loss = 0.01062455
Iteration 751, loss = 0.01058764
Iteration 752, loss = 0.01055812
Iteration 753, loss = 0.01058086
Iteration 754, loss = 0.01059381
Iteration 755, loss = 0.01061551
Iteration 756, loss = 0.01064057
Iteration 757, loss = 0.01071467
Iteration 758, loss = 0.01076464
Iteration 759, loss = 0.01079521
Iteration 760, loss = 0.01065469
Iteration 761, loss = 0.01043889
Iteration 762, loss = 0.01030630
Iteration 763, loss = 0.01042387
Iteration 764, loss = 0.01064665
Iteration 765, loss = 0.01056144
Iteration 766, loss = 0.01048045
Iteration 767, loss = 0.01033886
Iteration 768, loss = 0.01031749
Iteration 769, loss = 0.01020940
Iteration 770, loss = 0.01017954
Iteration 771, loss = 0.01015755
Iteration 772, loss = 0.01023005
Iteration 773, loss = 0.01022235
Iteration 774, loss = 0.01015116
Iteration 775, loss = 0.01011313
Iteration 776, loss = 0.01007390
Iteration 777, loss = 0.01003064
Iteration 778, loss = 0.01001309
Iteration 779, loss = 0.01001765
Iteration 780, loss = 0.00996011
Iteration 781, loss = 0.00994079
Iteration 782, loss = 0.00993883
Iteration 783, loss = 0.00995271
Iteration 784, loss = 0.00995914
Iteration 785, loss = 0.00989458
Iteration 786, loss = 0.00984910
Iteration 787, loss = 0.00981504
Iteration 788, loss = 0.00980762
Iteration 789, loss = 0.00981861
Iteration 790, loss = 0.00982593
Iteration 791, loss = 0.00981773
Iteration 792, loss = 0.00978982
Iteration 793, loss = 0.00976695
Iteration 794, loss = 0.00972486
Iteration 795, loss = 0.00967147
Iteration 796, loss = 0.00963862
Iteration 797, loss = 0.00961028
Iteration 798, loss = 0.00960237
Iteration 799, loss = 0.00959421
Iteration 800, loss = 0.00962511
Iteration 801, loss = 0.00959067
Iteration 802, loss = 0.00956853
Iteration 803, loss = 0.00955533
Iteration 804, loss = 0.00960483
Iteration 805, loss = 0.00948848
Iteration 806, loss = 0.00945934
Iteration 807, loss = 0.00953061
Iteration 808, loss = 0.00946624
Iteration 809, loss = 0.00942518
Iteration 810, loss = 0.00940199
Iteration 811, loss = 0.00942655
Iteration 812, loss = 0.00937504
Iteration 813, loss = 0.00944134
Iteration 814, loss = 0.00944279
Iteration 815, loss = 0.00933756
Iteration 816, loss = 0.00932988
Iteration 817, loss = 0.00929545
Iteration 818, loss = 0.00936669
Iteration 819, loss = 0.00924620
Iteration 820, loss = 0.00919225
Iteration 821, loss = 0.00923848
Iteration 822, loss = 0.00917335
Iteration 823, loss = 0.00919078
Iteration 824, loss = 0.00913507
Iteration 825, loss = 0.00911069
Iteration 826, loss = 0.00911062
Iteration 827, loss = 0.00917374
Iteration 828, loss = 0.00914978
Iteration 829, loss = 0.00905556
Iteration 830, loss = 0.00899775
Iteration 831, loss = 0.00896649
Iteration 832, loss = 0.00900788
Iteration 833, loss = 0.00918049
Iteration 834, loss = 0.00919708
Iteration 835, loss = 0.00915595
Iteration 836, loss = 0.00901576
Iteration 837, loss = 0.00893594
Iteration 838, loss = 0.00888220
Iteration 839, loss = 0.00887587
Iteration 840, loss = 0.00882818
Iteration 841, loss = 0.00881198
Iteration 842, loss = 0.00879917
Iteration 843, loss = 0.00877956
Iteration 844, loss = 0.00875167
Iteration 845, loss = 0.00873628
Iteration 846, loss = 0.00873483
Iteration 847, loss = 0.00873223
Iteration 848, loss = 0.00873574
Iteration 849, loss = 0.00869446
Iteration 850, loss = 0.00866456
Iteration 851, loss = 0.00862277
Iteration 852, loss = 0.00867873
Iteration 853, loss = 0.00858379
Iteration 854, loss = 0.00858924
Iteration 855, loss = 0.00859420
Iteration 856, loss = 0.00862546
Iteration 857, loss = 0.00860751
Iteration 858, loss = 0.00855103
Iteration 859, loss = 0.00851178
Iteration 860, loss = 0.00850111
Iteration 861, loss = 0.00850413
Iteration 862, loss = 0.00851687
Iteration 863, loss = 0.00853750
Iteration 864, loss = 0.00853022
Iteration 865, loss = 0.00851648
Iteration 866, loss = 0.00849032
Iteration 867, loss = 0.00847368
Iteration 868, loss = 0.00844795
Iteration 869, loss = 0.00842217
Iteration 870, loss = 0.00839096
Iteration 871, loss = 0.00838446
Iteration 872, loss = 0.00833934
Iteration 873, loss = 0.00832963
Iteration 874, loss = 0.00828779
Iteration 875, loss = 0.00828979
Iteration 876, loss = 0.00829907
Iteration 877, loss = 0.00827001
Iteration 878, loss = 0.00823333
Iteration 879, loss = 0.00820857
Iteration 880, loss = 0.00818945
Iteration 881, loss = 0.00818825
Iteration 882, loss = 0.00819158
Iteration 883, loss = 0.00819564
Iteration 884, loss = 0.00819443
Iteration 885, loss = 0.00821147
Iteration 886, loss = 0.00818900
Iteration 887, loss = 0.00822712
Iteration 888, loss = 0.00818502
Iteration 889, loss = 0.00814339
Iteration 890, loss = 0.00810390
Iteration 891, loss = 0.00806812
Iteration 892, loss = 0.00803124
Iteration 893, loss = 0.00801143
Iteration 894, loss = 0.00803977
Iteration 895, loss = 0.00799540
Iteration 896, loss = 0.00799193
Iteration 897, loss = 0.00797430
Iteration 898, loss = 0.00798765
Iteration 899, loss = 0.00797849
Iteration 900, loss = 0.00795069
Iteration 901, loss = 0.00793252
Iteration 902, loss = 0.00790843
Iteration 903, loss = 0.00791515
Iteration 904, loss = 0.00788942
Iteration 905, loss = 0.00786288
Iteration 906, loss = 0.00785808
Iteration 907, loss = 0.00784490
Iteration 908, loss = 0.00786388
Iteration 909, loss = 0.00785642
Iteration 910, loss = 0.00783957
Iteration 911, loss = 0.00783120
Iteration 912, loss = 0.00777126
Iteration 913, loss = 0.00772308
Iteration 914, loss = 0.00769621
Iteration 915, loss = 0.00770758
Iteration 916, loss = 0.00778965
Iteration 917, loss = 0.00782893
Iteration 918, loss = 0.00789623
Iteration 919, loss = 0.00793450
Iteration 920, loss = 0.00795046
Iteration 921, loss = 0.00783811
Iteration 922, loss = 0.00773793
Iteration 923, loss = 0.00769497
Iteration 924, loss = 0.00763130
Iteration 925, loss = 0.00759138
Iteration 926, loss = 0.00756739
Iteration 927, loss = 0.00756761
Iteration 928, loss = 0.00751465
Iteration 929, loss = 0.00752884
Iteration 930, loss = 0.00753964
Iteration 931, loss = 0.00747992
Iteration 932, loss = 0.00750351
Iteration 933, loss = 0.00748056
Iteration 934, loss = 0.00748413
Iteration 935, loss = 0.00744976
Iteration 936, loss = 0.00741516
Iteration 937, loss = 0.00739295
Iteration 938, loss = 0.00738827
Iteration 939, loss = 0.00740059
Iteration 940, loss = 0.00742145
Iteration 941, loss = 0.00743483
Iteration 942, loss = 0.00739003
Iteration 943, loss = 0.00734804
Iteration 944, loss = 0.00731534
Iteration 945, loss = 0.00730055
Iteration 946, loss = 0.00728298
Iteration 947, loss = 0.00728176
Iteration 948, loss = 0.00729118
Iteration 949, loss = 0.00724665
Iteration 950, loss = 0.00722796
Iteration 951, loss = 0.00721541
Iteration 952, loss = 0.00724418
Iteration 953, loss = 0.00724138
Iteration 954, loss = 0.00724266
Iteration 955, loss = 0.00723875
Iteration 956, loss = 0.00725645
Iteration 957, loss = 0.00720365
Iteration 958, loss = 0.00716551
Iteration 959, loss = 0.00715557
Iteration 960, loss = 0.00713868
Iteration 961, loss = 0.00714440
Iteration 962, loss = 0.00714823
Iteration 963, loss = 0.00710377
Iteration 964, loss = 0.00708096
Iteration 965, loss = 0.00705503
Iteration 966, loss = 0.00703264
Iteration 967, loss = 0.00705790
Iteration 968, loss = 0.00705232
Iteration 969, loss = 0.00702602
Iteration 970, loss = 0.00701624
Iteration 971, loss = 0.00700469
Iteration 972, loss = 0.00700505
Iteration 973, loss = 0.00700474
Iteration 974, loss = 0.00701788
Iteration 975, loss = 0.00703464
Iteration 976, loss = 0.00704109
Iteration 977, loss = 0.00708746
Iteration 978, loss = 0.00700328
Iteration 979, loss = 0.00690392
Iteration 980, loss = 0.00686231
Iteration 981, loss = 0.00681012
Iteration 982, loss = 0.00682036
Iteration 983, loss = 0.00681779
Iteration 984, loss = 0.00682656
Iteration 985, loss = 0.00679879
Iteration 986, loss = 0.00686195
Iteration 987, loss = 0.00690325
Iteration 988, loss = 0.00698482
Iteration 989, loss = 0.00701037
Iteration 990, loss = 0.00691977
Iteration 991, loss = 0.00680497
Iteration 992, loss = 0.00670666
Iteration 993, loss = 0.00675794
Iteration 994, loss = 0.00666933
Iteration 995, loss = 0.00665178
Iteration 996, loss = 0.00663056
Iteration 997, loss = 0.00659649
Iteration 998, loss = 0.00661087
Iteration 999, loss = 0.00662168
Iteration 1000, loss = 0.00661427
PARAMETROS DE INICIALIZACAO DA REDE
NUMERO DE NEURONIOS 
Camada de Entrada: 34
Camada Escondida: 3
Camada de Saida: 1

--- PARAMETROS DE CONFIGURACAO DA REDE ---
Numero de Epocas: 1000
Taxa de Aprendizado: adaptive
Taxa de Aprendizado Inicial: 0.3
METRICAS

RESULTADOS:

[0 0 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 1 1
 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 1 0 1
 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 0]
ACURACIA: 0.9339622641509434

