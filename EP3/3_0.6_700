Pesos Camada de Entrada: 
[[ 0.1589812  -0.02478354  0.07868866]
 [ 0.05098173  0.15890722 -0.04820931]
 [ 0.0563135   0.00106089  0.03220751]
 [ 0.11479586  0.19674041 -0.17072365]
 [-0.08469473 -0.04988795 -0.01090479]
 [-0.1252502  -0.07877275  0.02290396]
 [-0.08361106 -0.22137054 -0.18695999]
 [ 0.05522732 -0.11881628  0.20371463]
 [ 0.11917186  0.00233163  0.1085938 ]
 [ 0.10467148 -0.03597566 -0.08137162]
 [-0.01612685 -0.15514131  0.09623034]
 [-0.0917828   0.06767601 -0.18635099]
 [ 0.00479363  0.00192666  0.05466019]
 [ 0.19818762  0.11976999 -0.21391261]
 [-0.01740239 -0.23164526 -0.03891405]
 [-0.01953857  0.20903255 -0.01757027]
 [-0.16181587  0.06598234 -0.1451068 ]
 [ 0.15643848 -0.09543501  0.0723942 ]
 [-0.01693475  0.16570193  0.05521088]
 [-0.04975521 -0.13945845 -0.00215131]
 [-0.18538219  0.1553056   0.10834542]
 [ 0.19565246 -0.11215355 -0.1393167 ]
 [ 0.0825819   0.07076641 -0.1953984 ]
 [ 0.02200388  0.07159171  0.19090626]
 [-0.13004342 -0.02216576  0.10441784]
 [ 0.00956185  0.15749255 -0.0031604 ]
 [-0.12321605 -0.02841276 -0.12577325]
 [-0.0481577   0.22050595  0.223717  ]
 [-0.10231467  0.08957347  0.0189332 ]
 [ 0.11678125 -0.22499637  0.09484971]
 [-0.13532077 -0.17128464 -0.10695759]
 [-0.11333626  0.03460808  0.10191614]
 [ 0.14068089 -0.1514463  -0.22853605]
 [ 0.02358968  0.19255843  0.18887238]]
Bias Camada de Entrada: 
[-0.2235471  -0.20140275  0.08857027]
Pesos Camada Escondida: 
[[-0.11877416]
 [ 0.25149308]
 [-0.46878933]]
Bias Camada Escondida: 
[0.42586733]
Iteration 1, loss = 0.66211820
Iteration 2, loss = 0.64751543
Iteration 3, loss = 0.64127387
Iteration 4, loss = 0.63010197
Iteration 5, loss = 0.61307965
Iteration 6, loss = 0.58981902
Iteration 7, loss = 0.56049301
Iteration 8, loss = 0.52146254
Iteration 9, loss = 0.48245037
Iteration 10, loss = 0.44135489
Iteration 11, loss = 0.40710104
Iteration 12, loss = 0.38508581
Iteration 13, loss = 0.36340155
Iteration 14, loss = 0.35759397
Iteration 15, loss = 0.34109673
Iteration 16, loss = 0.32570486
Iteration 17, loss = 0.31190099
Iteration 18, loss = 0.30301475
Iteration 19, loss = 0.29467493
Iteration 20, loss = 0.29217067
Iteration 21, loss = 0.28128930
Iteration 22, loss = 0.27175977
Iteration 23, loss = 0.26329574
Iteration 24, loss = 0.25994227
Iteration 25, loss = 0.25127286
Iteration 26, loss = 0.24428710
Iteration 27, loss = 0.23988662
Iteration 28, loss = 0.23527744
Iteration 29, loss = 0.23320009
Iteration 30, loss = 0.23025155
Iteration 31, loss = 0.22472271
Iteration 32, loss = 0.22245506
Iteration 33, loss = 0.21572626
Iteration 34, loss = 0.21162961
Iteration 35, loss = 0.20983215
Iteration 36, loss = 0.20872783
Iteration 37, loss = 0.20364537
Iteration 38, loss = 0.20009480
Iteration 39, loss = 0.19780388
Iteration 40, loss = 0.19483841
Iteration 41, loss = 0.19111042
Iteration 42, loss = 0.18975057
Iteration 43, loss = 0.18885484
Iteration 44, loss = 0.17991028
Iteration 45, loss = 0.17932202
Iteration 46, loss = 0.17649822
Iteration 47, loss = 0.16311641
Iteration 48, loss = 0.16109045
Iteration 49, loss = 0.15802388
Iteration 50, loss = 0.15340277
Iteration 51, loss = 0.14408931
Iteration 52, loss = 0.13730775
Iteration 53, loss = 0.13148984
Iteration 54, loss = 0.12546262
Iteration 55, loss = 0.12179186
Iteration 56, loss = 0.12283179
Iteration 57, loss = 0.11916367
Iteration 58, loss = 0.10941389
Iteration 59, loss = 0.10561673
Iteration 60, loss = 0.10318709
Iteration 61, loss = 0.10051552
Iteration 62, loss = 0.09707642
Iteration 63, loss = 0.09331559
Iteration 64, loss = 0.09751959
Iteration 65, loss = 0.08914780
Iteration 66, loss = 0.08772119
Iteration 67, loss = 0.08495234
Iteration 68, loss = 0.08048989
Iteration 69, loss = 0.08025546
Iteration 70, loss = 0.07956009
Iteration 71, loss = 0.08759519
Iteration 72, loss = 0.07964562
Iteration 73, loss = 0.07585700
Iteration 74, loss = 0.07191349
Iteration 75, loss = 0.07210085
Iteration 76, loss = 0.06910492
Iteration 77, loss = 0.06752288
Iteration 78, loss = 0.06655167
Iteration 79, loss = 0.06547292
Iteration 80, loss = 0.06407077
Iteration 81, loss = 0.06272809
Iteration 82, loss = 0.06311656
Iteration 83, loss = 0.06030859
Iteration 84, loss = 0.06133722
Iteration 85, loss = 0.06037414
Iteration 86, loss = 0.06323853
Iteration 87, loss = 0.05932450
Iteration 88, loss = 0.05619492
Iteration 89, loss = 0.05549840
Iteration 90, loss = 0.05454698
Iteration 91, loss = 0.05426525
Iteration 92, loss = 0.05459299
Iteration 93, loss = 0.05304974
Iteration 94, loss = 0.05250062
Iteration 95, loss = 0.05312583
Iteration 96, loss = 0.05054852
Iteration 97, loss = 0.05144065
Iteration 98, loss = 0.05191142
Iteration 99, loss = 0.05101465
Iteration 100, loss = 0.04888014
Iteration 101, loss = 0.04818576
Iteration 102, loss = 0.05033024
Iteration 103, loss = 0.04897179
Iteration 104, loss = 0.04849864
Iteration 105, loss = 0.04658454
Iteration 106, loss = 0.04569891
Iteration 107, loss = 0.04567626
Iteration 108, loss = 0.04409443
Iteration 109, loss = 0.04262949
Iteration 110, loss = 0.04301267
Iteration 111, loss = 0.04093491
Iteration 112, loss = 0.04248295
Iteration 113, loss = 0.04254609
Iteration 114, loss = 0.04021528
Iteration 115, loss = 0.03908498
Iteration 116, loss = 0.03877210
Iteration 117, loss = 0.03842542
Iteration 118, loss = 0.03839009
Iteration 119, loss = 0.03777089
Iteration 120, loss = 0.03743029
Iteration 121, loss = 0.03713034
Iteration 122, loss = 0.03637324
Iteration 123, loss = 0.03621705
Iteration 124, loss = 0.03570930
Iteration 125, loss = 0.03575025
Iteration 126, loss = 0.03556879
Iteration 127, loss = 0.03456521
Iteration 128, loss = 0.03407055
Iteration 129, loss = 0.03350654
Iteration 130, loss = 0.03327787
Iteration 131, loss = 0.03312662
Iteration 132, loss = 0.03276114
Iteration 133, loss = 0.03220179
Iteration 134, loss = 0.03237071
Iteration 135, loss = 0.03254021
Iteration 136, loss = 0.03123466
Iteration 137, loss = 0.03043236
Iteration 138, loss = 0.03175115
Iteration 139, loss = 0.03088908
Iteration 140, loss = 0.03009256
Iteration 141, loss = 0.02944298
Iteration 142, loss = 0.02902616
Iteration 143, loss = 0.02859786
Iteration 144, loss = 0.02835185
Iteration 145, loss = 0.02845956
Iteration 146, loss = 0.02813927
Iteration 147, loss = 0.02779101
Iteration 148, loss = 0.02868415
Iteration 149, loss = 0.02756537
Iteration 150, loss = 0.02687428
Iteration 151, loss = 0.02697168
Iteration 152, loss = 0.02738562
Iteration 153, loss = 0.02768349
Iteration 154, loss = 0.02660171
Iteration 155, loss = 0.02585705
Iteration 156, loss = 0.02561931
Iteration 157, loss = 0.02490483
Iteration 158, loss = 0.02499578
Iteration 159, loss = 0.02486204
Iteration 160, loss = 0.02440892
Iteration 161, loss = 0.02397594
Iteration 162, loss = 0.02371117
Iteration 163, loss = 0.02324380
Iteration 164, loss = 0.02300683
Iteration 165, loss = 0.02310137
Iteration 166, loss = 0.02275644
Iteration 167, loss = 0.02317198
Iteration 168, loss = 0.02262532
Iteration 169, loss = 0.02211080
Iteration 170, loss = 0.02163161
Iteration 171, loss = 0.02132902
Iteration 172, loss = 0.02099042
Iteration 173, loss = 0.02098170
Iteration 174, loss = 0.02058102
Iteration 175, loss = 0.02036900
Iteration 176, loss = 0.02049950
Iteration 177, loss = 0.02030074
Iteration 178, loss = 0.02028523
Iteration 179, loss = 0.02000579
Iteration 180, loss = 0.01972071
Iteration 181, loss = 0.01927539
Iteration 182, loss = 0.01912152
Iteration 183, loss = 0.01935474
Iteration 184, loss = 0.01896274
Iteration 185, loss = 0.01865369
Iteration 186, loss = 0.01857481
Iteration 187, loss = 0.01937326
Iteration 188, loss = 0.01875050
Iteration 189, loss = 0.02083551
Iteration 190, loss = 0.01839508
Iteration 191, loss = 0.01774220
Iteration 192, loss = 0.01789655
Iteration 193, loss = 0.01803273
Iteration 194, loss = 0.01777845
Iteration 195, loss = 0.01747781
Iteration 196, loss = 0.01717292
Iteration 197, loss = 0.01681708
Iteration 198, loss = 0.01715007
Iteration 199, loss = 0.01657118
Iteration 200, loss = 0.01620944
Iteration 201, loss = 0.01626403
Iteration 202, loss = 0.01656003
Iteration 203, loss = 0.01669727
Iteration 204, loss = 0.01761277
Iteration 205, loss = 0.01678487
Iteration 206, loss = 0.01557086
Iteration 207, loss = 0.01522983
Iteration 208, loss = 0.01519963
Iteration 209, loss = 0.01507091
Iteration 210, loss = 0.01514626
Iteration 211, loss = 0.01492201
Iteration 212, loss = 0.01446359
Iteration 213, loss = 0.01437347
Iteration 214, loss = 0.01435562
Iteration 215, loss = 0.01417764
Iteration 216, loss = 0.01406137
Iteration 217, loss = 0.01406173
Iteration 218, loss = 0.01432008
Iteration 219, loss = 0.01445782
Iteration 220, loss = 0.01379600
Iteration 221, loss = 0.01340559
Iteration 222, loss = 0.01329493
Iteration 223, loss = 0.01334066
Iteration 224, loss = 0.01364466
Iteration 225, loss = 0.01309678
Iteration 226, loss = 0.01353685
Iteration 227, loss = 0.01360673
Iteration 228, loss = 0.01306743
Iteration 229, loss = 0.01268058
Iteration 230, loss = 0.01269996
Iteration 231, loss = 0.01214916
Iteration 232, loss = 0.01234562
Iteration 233, loss = 0.01227030
Iteration 234, loss = 0.01208139
Iteration 235, loss = 0.01198596
Iteration 236, loss = 0.01198460
Iteration 237, loss = 0.01205471
Iteration 238, loss = 0.01183423
Iteration 239, loss = 0.01152984
Iteration 240, loss = 0.01137928
Iteration 241, loss = 0.01126632
Iteration 242, loss = 0.01126070
Iteration 243, loss = 0.01112279
Iteration 244, loss = 0.01106002
Iteration 245, loss = 0.01097816
Iteration 246, loss = 0.01094818
Iteration 247, loss = 0.01091765
Iteration 248, loss = 0.01080626
Iteration 249, loss = 0.01073483
Iteration 250, loss = 0.01067478
Iteration 251, loss = 0.01051165
Iteration 252, loss = 0.01056352
Iteration 253, loss = 0.01122297
Iteration 254, loss = 0.01035159
Iteration 255, loss = 0.01018327
Iteration 256, loss = 0.01045201
Iteration 257, loss = 0.01007287
Iteration 258, loss = 0.01003584
Iteration 259, loss = 0.01024076
Iteration 260, loss = 0.01053235
Iteration 261, loss = 0.01034073
Iteration 262, loss = 0.00997237
Iteration 263, loss = 0.00977150
Iteration 264, loss = 0.00975627
Iteration 265, loss = 0.00954516
Iteration 266, loss = 0.00954711
Iteration 267, loss = 0.00954633
Iteration 268, loss = 0.00939171
Iteration 269, loss = 0.00934141
Iteration 270, loss = 0.00917691
Iteration 271, loss = 0.00911112
Iteration 272, loss = 0.00903846
Iteration 273, loss = 0.00897665
Iteration 274, loss = 0.00901147
Iteration 275, loss = 0.00887263
Iteration 276, loss = 0.00887259
Iteration 277, loss = 0.00885230
Iteration 278, loss = 0.00876505
Iteration 279, loss = 0.00870861
Iteration 280, loss = 0.00890925
Iteration 281, loss = 0.00867827
Iteration 282, loss = 0.00881259
Iteration 283, loss = 0.00892347
Iteration 284, loss = 0.00870746
Iteration 285, loss = 0.00840612
Iteration 286, loss = 0.00833662
Iteration 287, loss = 0.00881129
Iteration 288, loss = 0.00835080
Iteration 289, loss = 0.00819415
Iteration 290, loss = 0.00818697
Iteration 291, loss = 0.00815746
Iteration 292, loss = 0.00810071
Iteration 293, loss = 0.00808619
Iteration 294, loss = 0.00801920
Iteration 295, loss = 0.00797111
Iteration 296, loss = 0.00792314
Iteration 297, loss = 0.00781080
Iteration 298, loss = 0.00777569
Iteration 299, loss = 0.00772008
Iteration 300, loss = 0.00767421
Iteration 301, loss = 0.00767236
Iteration 302, loss = 0.00770745
Iteration 303, loss = 0.00757749
Iteration 304, loss = 0.00761218
Iteration 305, loss = 0.00749051
Iteration 306, loss = 0.00746604
Iteration 307, loss = 0.00741504
Iteration 308, loss = 0.00740039
Iteration 309, loss = 0.00728666
Iteration 310, loss = 0.00741763
Iteration 311, loss = 0.00746513
Iteration 312, loss = 0.00730128
Iteration 313, loss = 0.00718982
Iteration 314, loss = 0.00727148
Iteration 315, loss = 0.00751528
Iteration 316, loss = 0.00716898
Iteration 317, loss = 0.00700380
Iteration 318, loss = 0.00711535
Iteration 319, loss = 0.00696312
Iteration 320, loss = 0.00691962
Iteration 321, loss = 0.00697155
Iteration 322, loss = 0.00711256
Iteration 323, loss = 0.00709282
Iteration 324, loss = 0.00693858
Iteration 325, loss = 0.00676379
Iteration 326, loss = 0.00672560
Iteration 327, loss = 0.00672837
Iteration 328, loss = 0.00673700
Iteration 329, loss = 0.00674356
Iteration 330, loss = 0.00677254
Iteration 331, loss = 0.00673356
Iteration 332, loss = 0.00662720
Iteration 333, loss = 0.00653587
Iteration 334, loss = 0.00650675
Iteration 335, loss = 0.00648003
Iteration 336, loss = 0.00640216
Iteration 337, loss = 0.00639826
Iteration 338, loss = 0.00639973
Iteration 339, loss = 0.00637420
Iteration 340, loss = 0.00628741
Iteration 341, loss = 0.00624236
Iteration 342, loss = 0.00625209
Iteration 343, loss = 0.00618739
Iteration 344, loss = 0.00617449
Iteration 345, loss = 0.00618863
Iteration 346, loss = 0.00620134
Iteration 347, loss = 0.00614567
Iteration 348, loss = 0.00608117
Iteration 349, loss = 0.00606707
Iteration 350, loss = 0.00602276
Iteration 351, loss = 0.00596536
Iteration 352, loss = 0.00593104
Iteration 353, loss = 0.00594122
Iteration 354, loss = 0.00587827
Iteration 355, loss = 0.00585214
Iteration 356, loss = 0.00583218
Iteration 357, loss = 0.00583718
Iteration 358, loss = 0.00580600
Iteration 359, loss = 0.00577286
Iteration 360, loss = 0.00571495
Iteration 361, loss = 0.00580176
Iteration 362, loss = 0.00580700
Iteration 363, loss = 0.00569513
Iteration 364, loss = 0.00566930
Iteration 365, loss = 0.00562080
Iteration 366, loss = 0.00560006
Iteration 367, loss = 0.00557111
Iteration 368, loss = 0.00555208
Iteration 369, loss = 0.00552985
Iteration 370, loss = 0.00552137
Iteration 371, loss = 0.00549551
Iteration 372, loss = 0.00552165
Iteration 373, loss = 0.00555122
Iteration 374, loss = 0.00556474
Iteration 375, loss = 0.00558497
Iteration 376, loss = 0.00558808
Iteration 377, loss = 0.00551912
Iteration 378, loss = 0.00541292
Iteration 379, loss = 0.00531531
Iteration 380, loss = 0.00529829
Iteration 381, loss = 0.00538567
Iteration 382, loss = 0.00548344
Iteration 383, loss = 0.00538425
Iteration 384, loss = 0.00524319
Iteration 385, loss = 0.00518176
Iteration 386, loss = 0.00523386
Iteration 387, loss = 0.00530738
Iteration 388, loss = 0.00530442
Iteration 389, loss = 0.00528565
Iteration 390, loss = 0.00526957
Iteration 391, loss = 0.00522969
Iteration 392, loss = 0.00518355
Iteration 393, loss = 0.00512523
Iteration 394, loss = 0.00509906
Iteration 395, loss = 0.00508234
Iteration 396, loss = 0.00506679
Iteration 397, loss = 0.00498527
Iteration 398, loss = 0.00496115
Iteration 399, loss = 0.00500194
Iteration 400, loss = 0.00500090
Iteration 401, loss = 0.00496945
Iteration 402, loss = 0.00502805
Iteration 403, loss = 0.00524451
Iteration 404, loss = 0.00505549
Iteration 405, loss = 0.00492855
Iteration 406, loss = 0.00485128
Iteration 407, loss = 0.00479522
Iteration 408, loss = 0.00478896
Iteration 409, loss = 0.00484398
Iteration 410, loss = 0.00485518
Iteration 411, loss = 0.00474507
Iteration 412, loss = 0.00470582
Iteration 413, loss = 0.00470453
Iteration 414, loss = 0.00482515
Iteration 415, loss = 0.00470654
Iteration 416, loss = 0.00465518
Iteration 417, loss = 0.00463187
Iteration 418, loss = 0.00460636
Iteration 419, loss = 0.00459203
Iteration 420, loss = 0.00460493
Iteration 421, loss = 0.00458051
Iteration 422, loss = 0.00461340
Iteration 423, loss = 0.00453923
Iteration 424, loss = 0.00451502
Iteration 425, loss = 0.00449373
Iteration 426, loss = 0.00448405
Iteration 427, loss = 0.00446178
Iteration 428, loss = 0.00445290
Iteration 429, loss = 0.00445626
Iteration 430, loss = 0.00450860
Iteration 431, loss = 0.00456755
Iteration 432, loss = 0.00447447
Iteration 433, loss = 0.00440068
Iteration 434, loss = 0.00436616
Iteration 435, loss = 0.00435138
Iteration 436, loss = 0.00433689
Iteration 437, loss = 0.00432555
Iteration 438, loss = 0.00431686
Iteration 439, loss = 0.00430605
Iteration 440, loss = 0.00429345
Iteration 441, loss = 0.00427990
Iteration 442, loss = 0.00426615
Iteration 443, loss = 0.00425555
Iteration 444, loss = 0.00423614
Iteration 445, loss = 0.00422576
Iteration 446, loss = 0.00423751
Iteration 447, loss = 0.00418790
Iteration 448, loss = 0.00418039
Iteration 449, loss = 0.00417639
Iteration 450, loss = 0.00415712
Iteration 451, loss = 0.00415101
Iteration 452, loss = 0.00412613
Iteration 453, loss = 0.00412141
Iteration 454, loss = 0.00411192
Iteration 455, loss = 0.00411588
Iteration 456, loss = 0.00412831
Iteration 457, loss = 0.00409330
Iteration 458, loss = 0.00408294
Iteration 459, loss = 0.00405850
Iteration 460, loss = 0.00404738
Iteration 461, loss = 0.00403453
Iteration 462, loss = 0.00401012
Iteration 463, loss = 0.00400219
Iteration 464, loss = 0.00402408
Iteration 465, loss = 0.00404895
Iteration 466, loss = 0.00401117
Iteration 467, loss = 0.00394474
Iteration 468, loss = 0.00390925
Iteration 469, loss = 0.00397830
Iteration 470, loss = 0.00401645
Iteration 471, loss = 0.00397748
Iteration 472, loss = 0.00392234
Iteration 473, loss = 0.00389534
Iteration 474, loss = 0.00387704
Iteration 475, loss = 0.00388400
Iteration 476, loss = 0.00387732
Iteration 477, loss = 0.00386875
Iteration 478, loss = 0.00385817
Iteration 479, loss = 0.00384544
Iteration 480, loss = 0.00383144
Iteration 481, loss = 0.00381694
Iteration 482, loss = 0.00380635
Iteration 483, loss = 0.00378661
Iteration 484, loss = 0.00377019
Iteration 485, loss = 0.00376551
Iteration 486, loss = 0.00376763
Iteration 487, loss = 0.00379738
Iteration 488, loss = 0.00377066
Iteration 489, loss = 0.00375414
Iteration 490, loss = 0.00375502
Iteration 491, loss = 0.00373168
Iteration 492, loss = 0.00372796
Iteration 493, loss = 0.00371851
Iteration 494, loss = 0.00370202
Iteration 495, loss = 0.00371283
Iteration 496, loss = 0.00368011
Iteration 497, loss = 0.00367438
Iteration 498, loss = 0.00369538
Iteration 499, loss = 0.00369353
Iteration 500, loss = 0.00368236
Iteration 501, loss = 0.00362042
Iteration 502, loss = 0.00360129
Iteration 503, loss = 0.00356578
Iteration 504, loss = 0.00356301
Iteration 505, loss = 0.00356423
Iteration 506, loss = 0.00356827
Iteration 507, loss = 0.00357533
Iteration 508, loss = 0.00357499
Iteration 509, loss = 0.00356807
Iteration 510, loss = 0.00357824
Iteration 511, loss = 0.00357294
Iteration 512, loss = 0.00351431
Iteration 513, loss = 0.00347040
Iteration 514, loss = 0.00347778
Iteration 515, loss = 0.00350991
Iteration 516, loss = 0.00356772
Iteration 517, loss = 0.00359990
Iteration 518, loss = 0.00352741
Iteration 519, loss = 0.00344291
Iteration 520, loss = 0.00342645
Iteration 521, loss = 0.00339413
Iteration 522, loss = 0.00339064
Iteration 523, loss = 0.00338143
Iteration 524, loss = 0.00338163
Iteration 525, loss = 0.00337651
Iteration 526, loss = 0.00337258
Iteration 527, loss = 0.00336580
Iteration 528, loss = 0.00335506
Iteration 529, loss = 0.00334975
Iteration 530, loss = 0.00333805
Iteration 531, loss = 0.00333579
Iteration 532, loss = 0.00331744
Iteration 533, loss = 0.00330920
Iteration 534, loss = 0.00330259
Iteration 535, loss = 0.00329356
Iteration 536, loss = 0.00330117
Iteration 537, loss = 0.00327913
Iteration 538, loss = 0.00325767
Iteration 539, loss = 0.00324505
Iteration 540, loss = 0.00323619
Iteration 541, loss = 0.00323647
Iteration 542, loss = 0.00325371
Iteration 543, loss = 0.00322130
Iteration 544, loss = 0.00321217
Iteration 545, loss = 0.00319605
Iteration 546, loss = 0.00320079
Iteration 547, loss = 0.00319427
Iteration 548, loss = 0.00318710
Iteration 549, loss = 0.00317807
Iteration 550, loss = 0.00318288
Iteration 551, loss = 0.00318906
Iteration 552, loss = 0.00318826
Iteration 553, loss = 0.00317284
Iteration 554, loss = 0.00315735
Iteration 555, loss = 0.00315371
Iteration 556, loss = 0.00315974
Iteration 557, loss = 0.00316479
Iteration 558, loss = 0.00315580
Iteration 559, loss = 0.00314420
Iteration 560, loss = 0.00313147
Iteration 561, loss = 0.00311256
Iteration 562, loss = 0.00309578
Iteration 563, loss = 0.00307080
Iteration 564, loss = 0.00307684
Iteration 565, loss = 0.00305744
Iteration 566, loss = 0.00305203
Iteration 567, loss = 0.00304531
Iteration 568, loss = 0.00303875
Iteration 569, loss = 0.00304688
Iteration 570, loss = 0.00302022
Iteration 571, loss = 0.00301176
Iteration 572, loss = 0.00301992
Iteration 573, loss = 0.00302449
Iteration 574, loss = 0.00303661
Iteration 575, loss = 0.00302754
Iteration 576, loss = 0.00301042
Iteration 577, loss = 0.00300574
Iteration 578, loss = 0.00299457
Iteration 579, loss = 0.00297763
Iteration 580, loss = 0.00294179
Iteration 581, loss = 0.00300578
Iteration 582, loss = 0.00295151
Iteration 583, loss = 0.00294091
Iteration 584, loss = 0.00293200
Iteration 585, loss = 0.00292015
Iteration 586, loss = 0.00291931
Iteration 587, loss = 0.00292857
Iteration 588, loss = 0.00292623
Iteration 589, loss = 0.00292526
Iteration 590, loss = 0.00290665
Iteration 591, loss = 0.00289066
Iteration 592, loss = 0.00288692
Iteration 593, loss = 0.00287074
Iteration 594, loss = 0.00286491
Iteration 595, loss = 0.00285790
Iteration 596, loss = 0.00290150
Iteration 597, loss = 0.00285212
Iteration 598, loss = 0.00283211
Iteration 599, loss = 0.00282717
Iteration 600, loss = 0.00281848
Iteration 601, loss = 0.00281684
Iteration 602, loss = 0.00281236
Iteration 603, loss = 0.00280159
Iteration 604, loss = 0.00279633
Iteration 605, loss = 0.00280426
Iteration 606, loss = 0.00278404
Iteration 607, loss = 0.00278700
Iteration 608, loss = 0.00279244
Iteration 609, loss = 0.00279313
Iteration 610, loss = 0.00278283
Iteration 611, loss = 0.00277100
Iteration 612, loss = 0.00276143
Iteration 613, loss = 0.00275578
Iteration 614, loss = 0.00275603
Iteration 615, loss = 0.00276049
Iteration 616, loss = 0.00275423
Iteration 617, loss = 0.00273783
Iteration 618, loss = 0.00272692
Iteration 619, loss = 0.00274037
Iteration 620, loss = 0.00271020
Iteration 621, loss = 0.00270395
Iteration 622, loss = 0.00270268
Iteration 623, loss = 0.00269815
Iteration 624, loss = 0.00269618
Iteration 625, loss = 0.00269458
Iteration 626, loss = 0.00268822
Iteration 627, loss = 0.00268070
Iteration 628, loss = 0.00265571
Iteration 629, loss = 0.00265264
Iteration 630, loss = 0.00265787
Iteration 631, loss = 0.00265774
Iteration 632, loss = 0.00266276
Iteration 633, loss = 0.00265628
Iteration 634, loss = 0.00266244
Iteration 635, loss = 0.00265516
Iteration 636, loss = 0.00265614
Iteration 637, loss = 0.00263998
Iteration 638, loss = 0.00262502
Iteration 639, loss = 0.00261282
Iteration 640, loss = 0.00260032
Iteration 641, loss = 0.00259274
Iteration 642, loss = 0.00258710
Iteration 643, loss = 0.00258622
Iteration 644, loss = 0.00258690
Iteration 645, loss = 0.00258403
Iteration 646, loss = 0.00258067
Iteration 647, loss = 0.00257132
Iteration 648, loss = 0.00256945
Iteration 649, loss = 0.00257291
Iteration 650, loss = 0.00257748
Iteration 651, loss = 0.00259255
Iteration 652, loss = 0.00257273
Iteration 653, loss = 0.00257025
Iteration 654, loss = 0.00255024
Iteration 655, loss = 0.00254159
Iteration 656, loss = 0.00253443
Iteration 657, loss = 0.00252847
Iteration 658, loss = 0.00250954
Iteration 659, loss = 0.00250073
Iteration 660, loss = 0.00254591
Iteration 661, loss = 0.00253622
Iteration 662, loss = 0.00252648
Iteration 663, loss = 0.00251912
Iteration 664, loss = 0.00250587
Iteration 665, loss = 0.00249446
Iteration 666, loss = 0.00249101
Iteration 667, loss = 0.00250063
Iteration 668, loss = 0.00249705
Iteration 669, loss = 0.00247778
Iteration 670, loss = 0.00248661
Iteration 671, loss = 0.00245243
Iteration 672, loss = 0.00244454
Iteration 673, loss = 0.00244104
Iteration 674, loss = 0.00243780
Iteration 675, loss = 0.00242980
Iteration 676, loss = 0.00242940
Iteration 677, loss = 0.00242680
Iteration 678, loss = 0.00241480
Iteration 679, loss = 0.00242788
Iteration 680, loss = 0.00240901
Iteration 681, loss = 0.00240705
Iteration 682, loss = 0.00240717
Iteration 683, loss = 0.00240133
Iteration 684, loss = 0.00239692
Iteration 685, loss = 0.00239301
Iteration 686, loss = 0.00238915
Iteration 687, loss = 0.00238411
Iteration 688, loss = 0.00237993
Iteration 689, loss = 0.00237586
Iteration 690, loss = 0.00238373
Iteration 691, loss = 0.00236933
Iteration 692, loss = 0.00236071
Iteration 693, loss = 0.00235779
Iteration 694, loss = 0.00235287
Iteration 695, loss = 0.00235150
Iteration 696, loss = 0.00234576
Iteration 697, loss = 0.00233734
Iteration 698, loss = 0.00233314
Iteration 699, loss = 0.00232989
Iteration 700, loss = 0.00233397
PARAMETROS DE INICIALIZACAO DA REDE
NUMERO DE NEURONIOS 
Camada de Entrada: 34
Camada Escondida: 3
Camada de Saida: 1

--- PARAMETROS DE CONFIGURACAO DA REDE ---
Numero de Epocas: 700
Taxa de Aprendizado: adaptive
Taxa de Aprendizado Inicial: 0.6
METRICAS

RESULTADOS:

[0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 1 1
 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 1 0 1
 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 0]
ACURACIA: 0.9150943396226415

