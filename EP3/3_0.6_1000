Pesos Camada de Entrada: 
[[ 0.02243177  0.20944411 -0.22179538]
 [ 0.19884259 -0.06686411  0.02007651]
 [ 0.20357952 -0.07692578 -0.05569569]
 [-0.06233352  0.03450902  0.18837589]
 [-0.21718136  0.18337985  0.18788834]
 [ 0.15215111 -0.14968007 -0.09803717]
 [ 0.03035204 -0.02983832  0.19313647]
 [ 0.04423197 -0.06551159 -0.05467811]
 [ 0.22796174  0.13629019 -0.02637442]
 [-0.20387191 -0.07428912 -0.08334818]
 [ 0.01569324 -0.12066489 -0.02610628]
 [ 0.04771494 -0.20483816 -0.21357829]
 [-0.10164604 -0.07493751 -0.08791487]
 [-0.19757723 -0.01305533 -0.09364947]
 [ 0.01980462  0.08915227  0.16786235]
 [-0.0769264  -0.02373748 -0.19507146]
 [ 0.09407313  0.01943338  0.22350577]
 [-0.04444126 -0.10557164 -0.16272514]
 [-0.07615405  0.00418261 -0.04420329]
 [-0.14414246 -0.14729469  0.01914114]
 [-0.01407604 -0.08713021 -0.16813884]
 [-0.20388195  0.22473244 -0.22631186]
 [-0.18085751 -0.06120416  0.11429419]
 [ 0.10618237  0.11289715  0.02354725]
 [-0.17050663 -0.17580167  0.22382556]
 [-0.02631091 -0.20518731  0.16410127]
 [ 0.18368163  0.18086831  0.11673839]
 [-0.10134478  0.17895095  0.0862993 ]
 [ 0.05358271  0.21101321  0.15974151]
 [ 0.13365714  0.18481318  0.14528281]
 [-0.06794892 -0.23148372  0.14376369]
 [ 0.03893221 -0.15317567 -0.20942135]
 [ 0.15726264  0.12978593 -0.0753503 ]
 [ 0.20413214 -0.06857463 -0.17380324]]
Bias Camada de Entrada: 
[-0.0280751  -0.08010431 -0.08269742]
Pesos Camada Escondida: 
[[ 0.25702283]
 [-0.18377718]
 [-0.67932338]]
Bias Camada Escondida: 
[-0.21126573]
Iteration 1, loss = 0.78261924
Iteration 2, loss = 0.64939347
Iteration 3, loss = 0.66093901
Iteration 4, loss = 0.63613176
Iteration 5, loss = 0.61476686
Iteration 6, loss = 0.59412393
Iteration 7, loss = 0.56732833
Iteration 8, loss = 0.53472535
Iteration 9, loss = 0.49363474
Iteration 10, loss = 0.45191747
Iteration 11, loss = 0.41390901
Iteration 12, loss = 0.38108737
Iteration 13, loss = 0.35878941
Iteration 14, loss = 0.34420585
Iteration 15, loss = 0.33554609
Iteration 16, loss = 0.32210924
Iteration 17, loss = 0.30489986
Iteration 18, loss = 0.29412403
Iteration 19, loss = 0.28856713
Iteration 20, loss = 0.27354382
Iteration 21, loss = 0.26548707
Iteration 22, loss = 0.25794106
Iteration 23, loss = 0.25262918
Iteration 24, loss = 0.24895933
Iteration 25, loss = 0.23895445
Iteration 26, loss = 0.23544757
Iteration 27, loss = 0.23317154
Iteration 28, loss = 0.22521406
Iteration 29, loss = 0.22109214
Iteration 30, loss = 0.21246262
Iteration 31, loss = 0.20768073
Iteration 32, loss = 0.20375404
Iteration 33, loss = 0.19900336
Iteration 34, loss = 0.19760882
Iteration 35, loss = 0.18987651
Iteration 36, loss = 0.18259857
Iteration 37, loss = 0.17657600
Iteration 38, loss = 0.16954941
Iteration 39, loss = 0.16298299
Iteration 40, loss = 0.15764665
Iteration 41, loss = 0.15356071
Iteration 42, loss = 0.15005856
Iteration 43, loss = 0.14676452
Iteration 44, loss = 0.14260114
Iteration 45, loss = 0.13818997
Iteration 46, loss = 0.13424175
Iteration 47, loss = 0.13037987
Iteration 48, loss = 0.12739363
Iteration 49, loss = 0.12524247
Iteration 50, loss = 0.12269359
Iteration 51, loss = 0.11937375
Iteration 52, loss = 0.11626987
Iteration 53, loss = 0.11379522
Iteration 54, loss = 0.11294550
Iteration 55, loss = 0.11200061
Iteration 56, loss = 0.11064079
Iteration 57, loss = 0.10606118
Iteration 58, loss = 0.10529730
Iteration 59, loss = 0.10458565
Iteration 60, loss = 0.10233667
Iteration 61, loss = 0.09809180
Iteration 62, loss = 0.09783354
Iteration 63, loss = 0.09697813
Iteration 64, loss = 0.09317230
Iteration 65, loss = 0.09377991
Iteration 66, loss = 0.09352684
Iteration 67, loss = 0.09086127
Iteration 68, loss = 0.08854390
Iteration 69, loss = 0.08792181
Iteration 70, loss = 0.08644466
Iteration 71, loss = 0.08502684
Iteration 72, loss = 0.08349506
Iteration 73, loss = 0.08292733
Iteration 74, loss = 0.08171866
Iteration 75, loss = 0.08020817
Iteration 76, loss = 0.07867434
Iteration 77, loss = 0.07768848
Iteration 78, loss = 0.07658752
Iteration 79, loss = 0.07582985
Iteration 80, loss = 0.07465138
Iteration 81, loss = 0.07287893
Iteration 82, loss = 0.07122916
Iteration 83, loss = 0.07012637
Iteration 84, loss = 0.06948243
Iteration 85, loss = 0.06823538
Iteration 86, loss = 0.06694182
Iteration 87, loss = 0.06451072
Iteration 88, loss = 0.06587588
Iteration 89, loss = 0.06358273
Iteration 90, loss = 0.06091334
Iteration 91, loss = 0.05813151
Iteration 92, loss = 0.05679592
Iteration 93, loss = 0.05620593
Iteration 94, loss = 0.05426538
Iteration 95, loss = 0.05260567
Iteration 96, loss = 0.05195162
Iteration 97, loss = 0.05004174
Iteration 98, loss = 0.04983561
Iteration 99, loss = 0.04947019
Iteration 100, loss = 0.04864649
Iteration 101, loss = 0.04622610
Iteration 102, loss = 0.04751226
Iteration 103, loss = 0.04550216
Iteration 104, loss = 0.04394047
Iteration 105, loss = 0.04399475
Iteration 106, loss = 0.04244514
Iteration 107, loss = 0.04103896
Iteration 108, loss = 0.04016970
Iteration 109, loss = 0.03939971
Iteration 110, loss = 0.03860892
Iteration 111, loss = 0.03877568
Iteration 112, loss = 0.03851129
Iteration 113, loss = 0.03705296
Iteration 114, loss = 0.03703499
Iteration 115, loss = 0.03663791
Iteration 116, loss = 0.03548336
Iteration 117, loss = 0.03599127
Iteration 118, loss = 0.03436445
Iteration 119, loss = 0.03359495
Iteration 120, loss = 0.03222927
Iteration 121, loss = 0.03224015
Iteration 122, loss = 0.03147617
Iteration 123, loss = 0.03088532
Iteration 124, loss = 0.03052930
Iteration 125, loss = 0.03023819
Iteration 126, loss = 0.03009437
Iteration 127, loss = 0.02975224
Iteration 128, loss = 0.02930452
Iteration 129, loss = 0.02889818
Iteration 130, loss = 0.02846997
Iteration 131, loss = 0.02793318
Iteration 132, loss = 0.02749779
Iteration 133, loss = 0.02700306
Iteration 134, loss = 0.02665109
Iteration 135, loss = 0.02635880
Iteration 136, loss = 0.02631017
Iteration 137, loss = 0.02648691
Iteration 138, loss = 0.02689278
Iteration 139, loss = 0.02699388
Iteration 140, loss = 0.02585874
Iteration 141, loss = 0.02503920
Iteration 142, loss = 0.02480135
Iteration 143, loss = 0.02394613
Iteration 144, loss = 0.02368642
Iteration 145, loss = 0.02370259
Iteration 146, loss = 0.02360428
Iteration 147, loss = 0.02301082
Iteration 148, loss = 0.02257908
Iteration 149, loss = 0.02226444
Iteration 150, loss = 0.02231293
Iteration 151, loss = 0.02215894
Iteration 152, loss = 0.02173740
Iteration 153, loss = 0.02160594
Iteration 154, loss = 0.02145632
Iteration 155, loss = 0.02214342
Iteration 156, loss = 0.02192935
Iteration 157, loss = 0.02126068
Iteration 158, loss = 0.02027980
Iteration 159, loss = 0.01985777
Iteration 160, loss = 0.02034078
Iteration 161, loss = 0.02120602
Iteration 162, loss = 0.02092930
Iteration 163, loss = 0.01974674
Iteration 164, loss = 0.01896219
Iteration 165, loss = 0.01858706
Iteration 166, loss = 0.01850928
Iteration 167, loss = 0.01815462
Iteration 168, loss = 0.01812712
Iteration 169, loss = 0.01801097
Iteration 170, loss = 0.01799959
Iteration 171, loss = 0.01758455
Iteration 172, loss = 0.01757559
Iteration 173, loss = 0.01744741
Iteration 174, loss = 0.01828477
Iteration 175, loss = 0.01696832
Iteration 176, loss = 0.01674622
Iteration 177, loss = 0.01653593
Iteration 178, loss = 0.01658337
Iteration 179, loss = 0.01649151
Iteration 180, loss = 0.01636694
Iteration 181, loss = 0.01626599
Iteration 182, loss = 0.01569586
Iteration 183, loss = 0.01549589
Iteration 184, loss = 0.01592346
Iteration 185, loss = 0.01587235
Iteration 186, loss = 0.01561052
Iteration 187, loss = 0.01508137
Iteration 188, loss = 0.01505788
Iteration 189, loss = 0.01474714
Iteration 190, loss = 0.01472621
Iteration 191, loss = 0.01460446
Iteration 192, loss = 0.01425012
Iteration 193, loss = 0.01405605
Iteration 194, loss = 0.01393787
Iteration 195, loss = 0.01384302
Iteration 196, loss = 0.01387654
Iteration 197, loss = 0.01384231
Iteration 198, loss = 0.01370849
Iteration 199, loss = 0.01364785
Iteration 200, loss = 0.01345860
Iteration 201, loss = 0.01321917
Iteration 202, loss = 0.01309041
Iteration 203, loss = 0.01298663
Iteration 204, loss = 0.01283956
Iteration 205, loss = 0.01271546
Iteration 206, loss = 0.01257793
Iteration 207, loss = 0.01253693
Iteration 208, loss = 0.01253737
Iteration 209, loss = 0.01265347
Iteration 210, loss = 0.01226430
Iteration 211, loss = 0.01213069
Iteration 212, loss = 0.01221635
Iteration 213, loss = 0.01212863
Iteration 214, loss = 0.01195490
Iteration 215, loss = 0.01180381
Iteration 216, loss = 0.01180575
Iteration 217, loss = 0.01189297
Iteration 218, loss = 0.01161992
Iteration 219, loss = 0.01149993
Iteration 220, loss = 0.01147849
Iteration 221, loss = 0.01160672
Iteration 222, loss = 0.01134151
Iteration 223, loss = 0.01145901
Iteration 224, loss = 0.01128760
Iteration 225, loss = 0.01097736
Iteration 226, loss = 0.01087136
Iteration 227, loss = 0.01078160
Iteration 228, loss = 0.01083737
Iteration 229, loss = 0.01060721
Iteration 230, loss = 0.01052869
Iteration 231, loss = 0.01056092
Iteration 232, loss = 0.01050049
Iteration 233, loss = 0.01041390
Iteration 234, loss = 0.01029857
Iteration 235, loss = 0.01016703
Iteration 236, loss = 0.01016092
Iteration 237, loss = 0.01021356
Iteration 238, loss = 0.01044004
Iteration 239, loss = 0.01022344
Iteration 240, loss = 0.00984534
Iteration 241, loss = 0.00968611
Iteration 242, loss = 0.00983143
Iteration 243, loss = 0.01022819
Iteration 244, loss = 0.01057926
Iteration 245, loss = 0.00992974
Iteration 246, loss = 0.00954329
Iteration 247, loss = 0.00948906
Iteration 248, loss = 0.00964900
Iteration 249, loss = 0.00991755
Iteration 250, loss = 0.00988225
Iteration 251, loss = 0.00955057
Iteration 252, loss = 0.00918191
Iteration 253, loss = 0.00895105
Iteration 254, loss = 0.00890031
Iteration 255, loss = 0.00899743
Iteration 256, loss = 0.00907959
Iteration 257, loss = 0.00904249
Iteration 258, loss = 0.00888767
Iteration 259, loss = 0.00873115
Iteration 260, loss = 0.00866635
Iteration 261, loss = 0.00862048
Iteration 262, loss = 0.00861377
Iteration 263, loss = 0.00863553
Iteration 264, loss = 0.00863379
Iteration 265, loss = 0.00857911
Iteration 266, loss = 0.00850188
Iteration 267, loss = 0.00824463
Iteration 268, loss = 0.00821103
Iteration 269, loss = 0.00836678
Iteration 270, loss = 0.00826533
Iteration 271, loss = 0.00817043
Iteration 272, loss = 0.00807946
Iteration 273, loss = 0.00801889
Iteration 274, loss = 0.00796396
Iteration 275, loss = 0.00799961
Iteration 276, loss = 0.00813948
Iteration 277, loss = 0.00802910
Iteration 278, loss = 0.00782255
Iteration 279, loss = 0.00761392
Iteration 280, loss = 0.00770204
Iteration 281, loss = 0.00792281
Iteration 282, loss = 0.00763395
Iteration 283, loss = 0.00749692
Iteration 284, loss = 0.00748178
Iteration 285, loss = 0.00745886
Iteration 286, loss = 0.00741367
Iteration 287, loss = 0.00737256
Iteration 288, loss = 0.00734737
Iteration 289, loss = 0.00729930
Iteration 290, loss = 0.00719821
Iteration 291, loss = 0.00717749
Iteration 292, loss = 0.00717562
Iteration 293, loss = 0.00714672
Iteration 294, loss = 0.00708297
Iteration 295, loss = 0.00705622
Iteration 296, loss = 0.00708883
Iteration 297, loss = 0.00695358
Iteration 298, loss = 0.00686130
Iteration 299, loss = 0.00690134
Iteration 300, loss = 0.00697298
Iteration 301, loss = 0.00696925
Iteration 302, loss = 0.00692024
Iteration 303, loss = 0.00683502
Iteration 304, loss = 0.00679666
Iteration 305, loss = 0.00680958
Iteration 306, loss = 0.00677752
Iteration 307, loss = 0.00675022
Iteration 308, loss = 0.00666724
Iteration 309, loss = 0.00656310
Iteration 310, loss = 0.00652405
Iteration 311, loss = 0.00652114
Iteration 312, loss = 0.00656479
Iteration 313, loss = 0.00656149
Iteration 314, loss = 0.00633875
Iteration 315, loss = 0.00637007
Iteration 316, loss = 0.00646586
Iteration 317, loss = 0.00641941
Iteration 318, loss = 0.00633701
Iteration 319, loss = 0.00623238
Iteration 320, loss = 0.00623684
Iteration 321, loss = 0.00615974
Iteration 322, loss = 0.00612360
Iteration 323, loss = 0.00608969
Iteration 324, loss = 0.00605706
Iteration 325, loss = 0.00604270
Iteration 326, loss = 0.00603759
Iteration 327, loss = 0.00600325
Iteration 328, loss = 0.00601847
Iteration 329, loss = 0.00596534
Iteration 330, loss = 0.00590265
Iteration 331, loss = 0.00586863
Iteration 332, loss = 0.00586883
Iteration 333, loss = 0.00591700
Iteration 334, loss = 0.00593600
Iteration 335, loss = 0.00587499
Iteration 336, loss = 0.00582549
Iteration 337, loss = 0.00574791
Iteration 338, loss = 0.00575353
Iteration 339, loss = 0.00571055
Iteration 340, loss = 0.00569599
Iteration 341, loss = 0.00564653
Iteration 342, loss = 0.00562444
Iteration 343, loss = 0.00559220
Iteration 344, loss = 0.00557685
Iteration 345, loss = 0.00556990
Iteration 346, loss = 0.00555813
Iteration 347, loss = 0.00553870
Iteration 348, loss = 0.00551909
Iteration 349, loss = 0.00548198
Iteration 350, loss = 0.00551431
Iteration 351, loss = 0.00548241
Iteration 352, loss = 0.00545071
Iteration 353, loss = 0.00537414
Iteration 354, loss = 0.00532340
Iteration 355, loss = 0.00534395
Iteration 356, loss = 0.00541799
Iteration 357, loss = 0.00534848
Iteration 358, loss = 0.00532113
Iteration 359, loss = 0.00526574
Iteration 360, loss = 0.00522392
Iteration 361, loss = 0.00520285
Iteration 362, loss = 0.00516293
Iteration 363, loss = 0.00515146
Iteration 364, loss = 0.00513925
Iteration 365, loss = 0.00511569
Iteration 366, loss = 0.00511431
Iteration 367, loss = 0.00508117
Iteration 368, loss = 0.00506799
Iteration 369, loss = 0.00505292
Iteration 370, loss = 0.00505022
Iteration 371, loss = 0.00500353
Iteration 372, loss = 0.00498777
Iteration 373, loss = 0.00494396
Iteration 374, loss = 0.00493351
Iteration 375, loss = 0.00492125
Iteration 376, loss = 0.00490852
Iteration 377, loss = 0.00492847
Iteration 378, loss = 0.00491889
Iteration 379, loss = 0.00485482
Iteration 380, loss = 0.00479839
Iteration 381, loss = 0.00482767
Iteration 382, loss = 0.00487960
Iteration 383, loss = 0.00484991
Iteration 384, loss = 0.00481053
Iteration 385, loss = 0.00478081
Iteration 386, loss = 0.00474612
Iteration 387, loss = 0.00472646
Iteration 388, loss = 0.00470563
Iteration 389, loss = 0.00469472
Iteration 390, loss = 0.00469031
Iteration 391, loss = 0.00466319
Iteration 392, loss = 0.00463163
Iteration 393, loss = 0.00464241
Iteration 394, loss = 0.00463467
Iteration 395, loss = 0.00463111
Iteration 396, loss = 0.00460703
Iteration 397, loss = 0.00460412
Iteration 398, loss = 0.00457486
Iteration 399, loss = 0.00453307
Iteration 400, loss = 0.00447539
Iteration 401, loss = 0.00445559
Iteration 402, loss = 0.00446745
Iteration 403, loss = 0.00447224
Iteration 404, loss = 0.00443981
Iteration 405, loss = 0.00439813
Iteration 406, loss = 0.00437503
Iteration 407, loss = 0.00437697
Iteration 408, loss = 0.00439075
Iteration 409, loss = 0.00434188
Iteration 410, loss = 0.00433234
Iteration 411, loss = 0.00433267
Iteration 412, loss = 0.00437032
Iteration 413, loss = 0.00431870
Iteration 414, loss = 0.00426600
Iteration 415, loss = 0.00425301
Iteration 416, loss = 0.00435461
Iteration 417, loss = 0.00428777
Iteration 418, loss = 0.00426060
Iteration 419, loss = 0.00423950
Iteration 420, loss = 0.00420663
Iteration 421, loss = 0.00416973
Iteration 422, loss = 0.00417093
Iteration 423, loss = 0.00414455
Iteration 424, loss = 0.00413080
Iteration 425, loss = 0.00410259
Iteration 426, loss = 0.00409031
Iteration 427, loss = 0.00407164
Iteration 428, loss = 0.00407388
Iteration 429, loss = 0.00408524
Iteration 430, loss = 0.00405159
Iteration 431, loss = 0.00403074
Iteration 432, loss = 0.00400724
Iteration 433, loss = 0.00401169
Iteration 434, loss = 0.00403250
Iteration 435, loss = 0.00404959
Iteration 436, loss = 0.00403674
Iteration 437, loss = 0.00398975
Iteration 438, loss = 0.00397360
Iteration 439, loss = 0.00394096
Iteration 440, loss = 0.00391971
Iteration 441, loss = 0.00390724
Iteration 442, loss = 0.00389447
Iteration 443, loss = 0.00388676
Iteration 444, loss = 0.00387113
Iteration 445, loss = 0.00386222
Iteration 446, loss = 0.00385240
Iteration 447, loss = 0.00384973
Iteration 448, loss = 0.00382918
Iteration 449, loss = 0.00384261
Iteration 450, loss = 0.00384942
Iteration 451, loss = 0.00382998
Iteration 452, loss = 0.00382163
Iteration 453, loss = 0.00380383
Iteration 454, loss = 0.00378615
Iteration 455, loss = 0.00376834
Iteration 456, loss = 0.00375203
Iteration 457, loss = 0.00374037
Iteration 458, loss = 0.00373143
Iteration 459, loss = 0.00373341
Iteration 460, loss = 0.00370231
Iteration 461, loss = 0.00368890
Iteration 462, loss = 0.00369237
Iteration 463, loss = 0.00367930
Iteration 464, loss = 0.00365352
Iteration 465, loss = 0.00365002
Iteration 466, loss = 0.00364067
Iteration 467, loss = 0.00363406
Iteration 468, loss = 0.00363265
Iteration 469, loss = 0.00362946
Iteration 470, loss = 0.00360451
Iteration 471, loss = 0.00356921
Iteration 472, loss = 0.00356165
Iteration 473, loss = 0.00354377
Iteration 474, loss = 0.00354352
Iteration 475, loss = 0.00355325
Iteration 476, loss = 0.00351768
Iteration 477, loss = 0.00350438
Iteration 478, loss = 0.00350319
Iteration 479, loss = 0.00348809
Iteration 480, loss = 0.00348470
Iteration 481, loss = 0.00346447
Iteration 482, loss = 0.00345737
Iteration 483, loss = 0.00345067
Iteration 484, loss = 0.00344097
Iteration 485, loss = 0.00343901
Iteration 486, loss = 0.00342411
Iteration 487, loss = 0.00342281
Iteration 488, loss = 0.00340530
Iteration 489, loss = 0.00339931
Iteration 490, loss = 0.00338811
Iteration 491, loss = 0.00339802
Iteration 492, loss = 0.00339939
Iteration 493, loss = 0.00340476
Iteration 494, loss = 0.00336397
Iteration 495, loss = 0.00334336
Iteration 496, loss = 0.00336120
Iteration 497, loss = 0.00333698
Iteration 498, loss = 0.00333680
Iteration 499, loss = 0.00333341
Iteration 500, loss = 0.00331436
Iteration 501, loss = 0.00330450
Iteration 502, loss = 0.00329081
Iteration 503, loss = 0.00328094
Iteration 504, loss = 0.00327357
Iteration 505, loss = 0.00326364
Iteration 506, loss = 0.00325174
Iteration 507, loss = 0.00324530
Iteration 508, loss = 0.00323093
Iteration 509, loss = 0.00322641
Iteration 510, loss = 0.00322606
Iteration 511, loss = 0.00321902
Iteration 512, loss = 0.00321922
Iteration 513, loss = 0.00321347
Iteration 514, loss = 0.00321725
Iteration 515, loss = 0.00320987
Iteration 516, loss = 0.00319537
Iteration 517, loss = 0.00317891
Iteration 518, loss = 0.00315591
Iteration 519, loss = 0.00315333
Iteration 520, loss = 0.00314033
Iteration 521, loss = 0.00313309
Iteration 522, loss = 0.00312819
Iteration 523, loss = 0.00311305
Iteration 524, loss = 0.00310451
Iteration 525, loss = 0.00309549
Iteration 526, loss = 0.00309784
Iteration 527, loss = 0.00309660
Iteration 528, loss = 0.00311907
Iteration 529, loss = 0.00308617
Iteration 530, loss = 0.00307372
Iteration 531, loss = 0.00306200
Iteration 532, loss = 0.00305631
Iteration 533, loss = 0.00305565
Iteration 534, loss = 0.00305832
Iteration 535, loss = 0.00305710
Iteration 536, loss = 0.00303610
Iteration 537, loss = 0.00303070
Iteration 538, loss = 0.00302784
Iteration 539, loss = 0.00303334
Iteration 540, loss = 0.00301760
Iteration 541, loss = 0.00301439
Iteration 542, loss = 0.00299071
Iteration 543, loss = 0.00297281
Iteration 544, loss = 0.00297048
Iteration 545, loss = 0.00295712
Iteration 546, loss = 0.00295283
Iteration 547, loss = 0.00294526
Iteration 548, loss = 0.00295862
Iteration 549, loss = 0.00294719
Iteration 550, loss = 0.00293805
Iteration 551, loss = 0.00292821
Iteration 552, loss = 0.00291968
Iteration 553, loss = 0.00290080
Iteration 554, loss = 0.00289229
Iteration 555, loss = 0.00288485
Iteration 556, loss = 0.00289687
Iteration 557, loss = 0.00288505
Iteration 558, loss = 0.00287993
Iteration 559, loss = 0.00287970
Iteration 560, loss = 0.00287752
Iteration 561, loss = 0.00287804
Iteration 562, loss = 0.00284846
Iteration 563, loss = 0.00284925
Iteration 564, loss = 0.00283540
Iteration 565, loss = 0.00282597
Iteration 566, loss = 0.00282111
Iteration 567, loss = 0.00281948
Iteration 568, loss = 0.00281325
Iteration 569, loss = 0.00282194
Iteration 570, loss = 0.00280980
Iteration 571, loss = 0.00279664
Iteration 572, loss = 0.00278897
Iteration 573, loss = 0.00277545
Iteration 574, loss = 0.00277152
Iteration 575, loss = 0.00275944
Iteration 576, loss = 0.00275452
Iteration 577, loss = 0.00275433
Iteration 578, loss = 0.00275779
Iteration 579, loss = 0.00277160
Iteration 580, loss = 0.00275763
Iteration 581, loss = 0.00275222
Iteration 582, loss = 0.00273908
Iteration 583, loss = 0.00272980
Iteration 584, loss = 0.00271965
Iteration 585, loss = 0.00271349
Iteration 586, loss = 0.00269630
Iteration 587, loss = 0.00270382
Iteration 588, loss = 0.00269478
Iteration 589, loss = 0.00268777
Iteration 590, loss = 0.00268414
Iteration 591, loss = 0.00267511
Iteration 592, loss = 0.00267029
Iteration 593, loss = 0.00265946
Iteration 594, loss = 0.00265520
Iteration 595, loss = 0.00266015
Iteration 596, loss = 0.00264218
Iteration 597, loss = 0.00263074
Iteration 598, loss = 0.00261749
Iteration 599, loss = 0.00261619
Iteration 600, loss = 0.00262114
Iteration 601, loss = 0.00262735
Iteration 602, loss = 0.00263584
Iteration 603, loss = 0.00265680
Iteration 604, loss = 0.00261938
Iteration 605, loss = 0.00260306
Iteration 606, loss = 0.00258274
Iteration 607, loss = 0.00257751
Iteration 608, loss = 0.00257095
Iteration 609, loss = 0.00256074
Iteration 610, loss = 0.00255895
Iteration 611, loss = 0.00255499
Iteration 612, loss = 0.00255486
Iteration 613, loss = 0.00253914
Iteration 614, loss = 0.00253144
Iteration 615, loss = 0.00253188
Iteration 616, loss = 0.00252127
Iteration 617, loss = 0.00252175
Iteration 618, loss = 0.00252076
Iteration 619, loss = 0.00251314
Iteration 620, loss = 0.00250929
Iteration 621, loss = 0.00250369
Iteration 622, loss = 0.00249117
Iteration 623, loss = 0.00249373
Iteration 624, loss = 0.00248312
Iteration 625, loss = 0.00248851
Iteration 626, loss = 0.00248632
Iteration 627, loss = 0.00249034
Iteration 628, loss = 0.00249477
Iteration 629, loss = 0.00249552
Iteration 630, loss = 0.00248053
Iteration 631, loss = 0.00247277
Iteration 632, loss = 0.00246320
Iteration 633, loss = 0.00246135
Iteration 634, loss = 0.00245351
Iteration 635, loss = 0.00244595
Iteration 636, loss = 0.00243973
Iteration 637, loss = 0.00243112
Iteration 638, loss = 0.00242763
Iteration 639, loss = 0.00241567
Iteration 640, loss = 0.00241857
Iteration 641, loss = 0.00240046
Iteration 642, loss = 0.00239576
Iteration 643, loss = 0.00239255
Iteration 644, loss = 0.00239652
Iteration 645, loss = 0.00239915
Iteration 646, loss = 0.00240416
Iteration 647, loss = 0.00238680
Iteration 648, loss = 0.00237324
Iteration 649, loss = 0.00235523
Iteration 650, loss = 0.00236186
Iteration 651, loss = 0.00237202
Iteration 652, loss = 0.00235260
Iteration 653, loss = 0.00234809
Iteration 654, loss = 0.00233946
Iteration 655, loss = 0.00233518
Iteration 656, loss = 0.00232759
Iteration 657, loss = 0.00232799
Iteration 658, loss = 0.00232490
Iteration 659, loss = 0.00232261
Iteration 660, loss = 0.00232346
Iteration 661, loss = 0.00231325
Iteration 662, loss = 0.00230617
Iteration 663, loss = 0.00230258
Iteration 664, loss = 0.00229802
Iteration 665, loss = 0.00229896
Iteration 666, loss = 0.00228939
Iteration 667, loss = 0.00228505
Iteration 668, loss = 0.00228214
Iteration 669, loss = 0.00228259
Iteration 670, loss = 0.00227423
Iteration 671, loss = 0.00226876
Iteration 672, loss = 0.00226535
Iteration 673, loss = 0.00227362
Iteration 674, loss = 0.00225646
Iteration 675, loss = 0.00224785
Iteration 676, loss = 0.00224050
Iteration 677, loss = 0.00223783
Iteration 678, loss = 0.00225833
Iteration 679, loss = 0.00224676
Iteration 680, loss = 0.00223715
Iteration 681, loss = 0.00222834
Iteration 682, loss = 0.00222665
Iteration 683, loss = 0.00222074
Iteration 684, loss = 0.00221049
Iteration 685, loss = 0.00222321
Iteration 686, loss = 0.00221399
Iteration 687, loss = 0.00221006
Iteration 688, loss = 0.00220925
Iteration 689, loss = 0.00220864
Iteration 690, loss = 0.00221229
Iteration 691, loss = 0.00218947
Iteration 692, loss = 0.00219286
Iteration 693, loss = 0.00217815
Iteration 694, loss = 0.00218788
Iteration 695, loss = 0.00217593
Iteration 696, loss = 0.00217202
Iteration 697, loss = 0.00216926
Iteration 698, loss = 0.00216316
Iteration 699, loss = 0.00215498
Iteration 700, loss = 0.00214758
Iteration 701, loss = 0.00214104
Iteration 702, loss = 0.00215879
Iteration 703, loss = 0.00218497
Iteration 704, loss = 0.00221743
Iteration 705, loss = 0.00218893
Iteration 706, loss = 0.00216050
Iteration 707, loss = 0.00213406
Iteration 708, loss = 0.00213159
Iteration 709, loss = 0.00211137
Iteration 710, loss = 0.00210931
Iteration 711, loss = 0.00211872
Iteration 712, loss = 0.00211559
Iteration 713, loss = 0.00210782
Iteration 714, loss = 0.00210138
Iteration 715, loss = 0.00209528
Iteration 716, loss = 0.00209015
Iteration 717, loss = 0.00208588
Iteration 718, loss = 0.00208200
Iteration 719, loss = 0.00207657
Iteration 720, loss = 0.00207519
Iteration 721, loss = 0.00207654
Iteration 722, loss = 0.00207809
Iteration 723, loss = 0.00208221
Iteration 724, loss = 0.00208573
Iteration 725, loss = 0.00208475
Iteration 726, loss = 0.00207603
Iteration 727, loss = 0.00206703
Iteration 728, loss = 0.00205810
Iteration 729, loss = 0.00205423
Iteration 730, loss = 0.00205078
Iteration 731, loss = 0.00205263
Iteration 732, loss = 0.00204790
Iteration 733, loss = 0.00204481
Iteration 734, loss = 0.00204232
Iteration 735, loss = 0.00204311
Iteration 736, loss = 0.00204164
Iteration 737, loss = 0.00204101
Iteration 738, loss = 0.00202992
Iteration 739, loss = 0.00201194
Iteration 740, loss = 0.00200918
Iteration 741, loss = 0.00200902
Iteration 742, loss = 0.00201343
Iteration 743, loss = 0.00202276
Iteration 744, loss = 0.00201253
Iteration 745, loss = 0.00199955
Iteration 746, loss = 0.00199071
Iteration 747, loss = 0.00198683
Iteration 748, loss = 0.00198514
Iteration 749, loss = 0.00198663
Iteration 750, loss = 0.00198877
Iteration 751, loss = 0.00197998
Iteration 752, loss = 0.00197501
Iteration 753, loss = 0.00197056
Iteration 754, loss = 0.00196606
Iteration 755, loss = 0.00196006
Iteration 756, loss = 0.00195649
Iteration 757, loss = 0.00195447
Iteration 758, loss = 0.00195206
Iteration 759, loss = 0.00194959
Iteration 760, loss = 0.00194809
Iteration 761, loss = 0.00194555
Iteration 762, loss = 0.00194363
Iteration 763, loss = 0.00194252
Iteration 764, loss = 0.00193827
Iteration 765, loss = 0.00193546
Iteration 766, loss = 0.00193083
Iteration 767, loss = 0.00192713
Iteration 768, loss = 0.00192343
Iteration 769, loss = 0.00192032
Iteration 770, loss = 0.00191935
Iteration 771, loss = 0.00191802
Iteration 772, loss = 0.00192047
Iteration 773, loss = 0.00191837
Iteration 774, loss = 0.00191232
Iteration 775, loss = 0.00191353
Iteration 776, loss = 0.00190258
Iteration 777, loss = 0.00189739
Iteration 778, loss = 0.00189421
Iteration 779, loss = 0.00189170
Iteration 780, loss = 0.00191560
Iteration 781, loss = 0.00190417
Iteration 782, loss = 0.00190031
Iteration 783, loss = 0.00189871
Iteration 784, loss = 0.00189496
Iteration 785, loss = 0.00189280
Iteration 786, loss = 0.00188795
Iteration 787, loss = 0.00188349
Iteration 788, loss = 0.00187524
Iteration 789, loss = 0.00186828
Iteration 790, loss = 0.00186746
Iteration 791, loss = 0.00186243
Iteration 792, loss = 0.00185898
Iteration 793, loss = 0.00185695
Iteration 794, loss = 0.00185464
Iteration 795, loss = 0.00185244
Iteration 796, loss = 0.00184941
Iteration 797, loss = 0.00184676
Iteration 798, loss = 0.00184740
Iteration 799, loss = 0.00183918
Iteration 800, loss = 0.00182960
Iteration 801, loss = 0.00182853
Iteration 802, loss = 0.00182288
Iteration 803, loss = 0.00182018
Iteration 804, loss = 0.00181827
Iteration 805, loss = 0.00181702
Iteration 806, loss = 0.00182100
Iteration 807, loss = 0.00181578
Iteration 808, loss = 0.00181254
Iteration 809, loss = 0.00181344
Iteration 810, loss = 0.00181570
Iteration 811, loss = 0.00182170
Iteration 812, loss = 0.00181165
Iteration 813, loss = 0.00180356
Iteration 814, loss = 0.00179718
Iteration 815, loss = 0.00179132
Iteration 816, loss = 0.00178804
Iteration 817, loss = 0.00179091
Iteration 818, loss = 0.00178240
Iteration 819, loss = 0.00178029
Iteration 820, loss = 0.00177432
Iteration 821, loss = 0.00177476
Iteration 822, loss = 0.00176823
Iteration 823, loss = 0.00176685
Iteration 824, loss = 0.00176976
Iteration 825, loss = 0.00176091
Iteration 826, loss = 0.00176801
Iteration 827, loss = 0.00175710
Iteration 828, loss = 0.00175215
Iteration 829, loss = 0.00174936
Iteration 830, loss = 0.00175295
Iteration 831, loss = 0.00175714
Iteration 832, loss = 0.00175324
Iteration 833, loss = 0.00174908
Iteration 834, loss = 0.00174184
Iteration 835, loss = 0.00173675
Iteration 836, loss = 0.00173392
Iteration 837, loss = 0.00173145
Iteration 838, loss = 0.00172913
Iteration 839, loss = 0.00172935
Iteration 840, loss = 0.00172923
Iteration 841, loss = 0.00172783
Iteration 842, loss = 0.00172750
Iteration 843, loss = 0.00172122
Iteration 844, loss = 0.00171776
Iteration 845, loss = 0.00171466
Iteration 846, loss = 0.00171295
Iteration 847, loss = 0.00170984
Iteration 848, loss = 0.00170778
Iteration 849, loss = 0.00170635
Iteration 850, loss = 0.00170913
Iteration 851, loss = 0.00170205
Iteration 852, loss = 0.00170076
Iteration 853, loss = 0.00170222
Iteration 854, loss = 0.00169987
Iteration 855, loss = 0.00170604
Iteration 856, loss = 0.00169564
Iteration 857, loss = 0.00169071
Iteration 858, loss = 0.00168365
Iteration 859, loss = 0.00167862
Iteration 860, loss = 0.00167475
Iteration 861, loss = 0.00167226
Iteration 862, loss = 0.00167398
Iteration 863, loss = 0.00167290
Iteration 864, loss = 0.00167285
Iteration 865, loss = 0.00167121
Iteration 866, loss = 0.00167074
Iteration 867, loss = 0.00166709
Iteration 868, loss = 0.00166656
Iteration 869, loss = 0.00166372
Iteration 870, loss = 0.00166187
Iteration 871, loss = 0.00166044
Iteration 872, loss = 0.00166058
Iteration 873, loss = 0.00165389
Iteration 874, loss = 0.00164987
Iteration 875, loss = 0.00164838
Iteration 876, loss = 0.00164321
Iteration 877, loss = 0.00164590
Iteration 878, loss = 0.00163945
Iteration 879, loss = 0.00163736
Iteration 880, loss = 0.00163299
Iteration 881, loss = 0.00163108
Iteration 882, loss = 0.00162653
Iteration 883, loss = 0.00162592
Iteration 884, loss = 0.00162390
Iteration 885, loss = 0.00162066
Iteration 886, loss = 0.00161810
Iteration 887, loss = 0.00161446
Iteration 888, loss = 0.00161305
Iteration 889, loss = 0.00161165
Iteration 890, loss = 0.00160881
Iteration 891, loss = 0.00160705
Iteration 892, loss = 0.00160676
Iteration 893, loss = 0.00160318
Iteration 894, loss = 0.00160227
Iteration 895, loss = 0.00160337
Iteration 896, loss = 0.00159995
Iteration 897, loss = 0.00159918
Iteration 898, loss = 0.00159972
Iteration 899, loss = 0.00159272
Iteration 900, loss = 0.00159605
Iteration 901, loss = 0.00158984
Iteration 902, loss = 0.00158791
Iteration 903, loss = 0.00158775
Iteration 904, loss = 0.00158621
Iteration 905, loss = 0.00158607
Iteration 906, loss = 0.00158689
Iteration 907, loss = 0.00158428
Iteration 908, loss = 0.00158190
Iteration 909, loss = 0.00158001
Iteration 910, loss = 0.00157622
Iteration 911, loss = 0.00157663
Iteration 912, loss = 0.00157109
Iteration 913, loss = 0.00156939
Iteration 914, loss = 0.00156498
Iteration 915, loss = 0.00156493
Iteration 916, loss = 0.00155995
Iteration 917, loss = 0.00155766
Iteration 918, loss = 0.00155467
Iteration 919, loss = 0.00155234
Iteration 920, loss = 0.00155161
Iteration 921, loss = 0.00155000
Iteration 922, loss = 0.00154551
Iteration 923, loss = 0.00154382
Iteration 924, loss = 0.00154406
Iteration 925, loss = 0.00154239
Iteration 926, loss = 0.00154303
Iteration 927, loss = 0.00154346
Iteration 928, loss = 0.00154420
Iteration 929, loss = 0.00154294
Iteration 930, loss = 0.00154424
Iteration 931, loss = 0.00153529
Iteration 932, loss = 0.00153012
Iteration 933, loss = 0.00152414
Iteration 934, loss = 0.00152297
Iteration 935, loss = 0.00152308
Iteration 936, loss = 0.00151983
Iteration 937, loss = 0.00151742
Iteration 938, loss = 0.00151344
Iteration 939, loss = 0.00151045
Iteration 940, loss = 0.00151078
Iteration 941, loss = 0.00150672
Iteration 942, loss = 0.00150567
Iteration 943, loss = 0.00151200
Iteration 944, loss = 0.00151355
Iteration 945, loss = 0.00151198
Iteration 946, loss = 0.00150987
Iteration 947, loss = 0.00150733
Iteration 948, loss = 0.00150389
Iteration 949, loss = 0.00149971
Iteration 950, loss = 0.00149634
Iteration 951, loss = 0.00149361
Iteration 952, loss = 0.00149109
Iteration 953, loss = 0.00148907
Iteration 954, loss = 0.00148900
Iteration 955, loss = 0.00148657
Iteration 956, loss = 0.00148377
Iteration 957, loss = 0.00147975
Iteration 958, loss = 0.00147664
Iteration 959, loss = 0.00147809
Iteration 960, loss = 0.00147090
Iteration 961, loss = 0.00146876
Iteration 962, loss = 0.00146702
Iteration 963, loss = 0.00146539
Iteration 964, loss = 0.00146298
Iteration 965, loss = 0.00146164
Iteration 966, loss = 0.00146139
Iteration 967, loss = 0.00145996
Iteration 968, loss = 0.00146170
Iteration 969, loss = 0.00145962
Iteration 970, loss = 0.00146155
Iteration 971, loss = 0.00145680
Iteration 972, loss = 0.00145343
Iteration 973, loss = 0.00144968
Iteration 974, loss = 0.00144625
Iteration 975, loss = 0.00144422
Iteration 976, loss = 0.00144189
Iteration 977, loss = 0.00144380
Iteration 978, loss = 0.00144361
Iteration 979, loss = 0.00144130
Iteration 980, loss = 0.00143909
Iteration 981, loss = 0.00143736
Iteration 982, loss = 0.00143533
Iteration 983, loss = 0.00143449
Iteration 984, loss = 0.00143017
Iteration 985, loss = 0.00142798
Iteration 986, loss = 0.00142992
Iteration 987, loss = 0.00142534
Iteration 988, loss = 0.00142193
Iteration 989, loss = 0.00142567
Iteration 990, loss = 0.00141900
Iteration 991, loss = 0.00141797
Iteration 992, loss = 0.00141914
Iteration 993, loss = 0.00141659
Iteration 994, loss = 0.00141505
Iteration 995, loss = 0.00141438
Iteration 996, loss = 0.00141307
Iteration 997, loss = 0.00141137
Iteration 998, loss = 0.00141083
Iteration 999, loss = 0.00140711
Iteration 1000, loss = 0.00140515
PARAMETROS DE INICIALIZACAO DA REDE
NUMERO DE NEURONIOS 
Camada de Entrada: 34
Camada Escondida: 3
Camada de Saida: 1

--- PARAMETROS DE CONFIGURACAO DA REDE ---
Numero de Epocas: 1000
Taxa de Aprendizado: adaptive
Taxa de Aprendizado Inicial: 0.6
METRICAS

RESULTADOS:

[0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 1 1
 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1
 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 0]
ACURACIA: 0.9339622641509434

